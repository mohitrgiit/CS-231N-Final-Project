{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import util\n",
    "\n",
    "address = '../../data/'\n",
    "file_names = {}\n",
    "file_names['images'] = 'full_data.npy'\n",
    "file_names['subs'] = 'full_subredditlabels'\n",
    "file_names['dict'] = 'full_subredditIndex'\n",
    "file_names['nsfw'] = 'full_nsfwlabels'\n",
    "data, dictionary = util.import_dataset(address, file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25450, 128, 128, 3)\n",
      "(3181, 128, 128, 3)\n",
      "(3182, 128, 128, 3)\n",
      "(25450,)\n",
      "(3181,)\n",
      "(3182,)\n"
     ]
    }
   ],
   "source": [
    "print(data.X_train.shape)\n",
    "print(data.X_val.shape)\n",
    "print(data.X_test.shape)\n",
    "print(data.y_train.shape)\n",
    "print(data.y_val.shape)\n",
    "print(data.y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from model import Model, lazy_property\n",
    "\n",
    "class GoogleNet(Model):\n",
    "    def __init__(self, model_config):\n",
    "        Model.__init__(self, model_config)\n",
    "    \n",
    "    def inception(self, input_layer, num_1x1, num_3x3_reduce, num_3x3, num_double_3x3_reduce, num_double_3x3, \n",
    "                  pool_type, proj_size, strided):\n",
    "        strides = [2, 2] if strided else [1, 1]  # last layer strides (before concatenation)\n",
    "\n",
    "        if num_1x1 > 0:\n",
    "            inception_1_conv1 = tf.layers.conv2d(input_layer, num_1x1, [1, 1], strides=strides, padding=\"SAME\")\n",
    "            inception_1_bn1 = tf.layers.batch_normalization(inception_1_conv1, training=self.is_training_placeholder)\n",
    "            inception_1 = tf.nn.relu(inception_1_bn1)\n",
    "\n",
    "        inception_2_conv1 = tf.layers.conv2d(input_layer, num_3x3_reduce, [1, 1], strides=[1, 1], padding=\"SAME\", activation=tf.nn.relu)\n",
    "        inception_2_conv2 = tf.layers.conv2d(inception_2_conv1, num_3x3, [3, 3], strides=strides, padding=\"SAME\")\n",
    "        inception_2_bn1 = tf.layers.batch_normalization(inception_2_conv2, training=self.is_training_placeholder)\n",
    "        inception_2 = tf.nn.relu(inception_2_bn1)\n",
    "\n",
    "        inception_3_conv1 = tf.layers.conv2d(input_layer, 64, [1, 1], strides=[1, 1], padding=\"SAME\", activation=tf.nn.relu)\n",
    "        inception_3_conv2 = tf.layers.conv2d(inception_3_conv1, 96, [3, 3], strides=[1, 1], padding=\"SAME\", activation=tf.nn.relu)\n",
    "        inception_3_conv3 = tf.layers.conv2d(inception_3_conv2, 96, [3, 3], strides=strides, padding=\"SAME\")\n",
    "        inception_3_bn1 = tf.layers.batch_normalization(inception_3_conv3, training=self.is_training_placeholder)\n",
    "        inception_3 = tf.nn.relu(inception_3_bn1)\n",
    "\n",
    "        inception_4_pool1 = tf.nn.pool(input_layer, [3, 3], pool_type, \"SAME\", strides=strides)\n",
    "        if proj_size == 0:\n",
    "            inception_4 = tf.nn.relu(inception_4_pool1)  # pass through layer if proj_size is 0\n",
    "        else:\n",
    "            inception_4_conv1 = tf.layers.conv2d(inception_4_pool1, proj_size, [1, 1], padding=\"SAME\")\n",
    "            inception_4_bn1 = tf.layers.batch_normalization(inception_4_conv1, training=self.is_training_placeholder)\n",
    "            inception_4 = tf.nn.relu(inception_4_bn1)\n",
    "\n",
    "        if num_1x1 > 0:\n",
    "            inception_out = tf.concat([inception_1, inception_2, inception_3, inception_4], -1)\n",
    "        else:\n",
    "            inception_out = tf.concat([inception_2, inception_3, inception_4], -1)\n",
    "        return inception_out\n",
    "    \n",
    "    @lazy_property\n",
    "    def prediction(self):\n",
    "        conv_1 = tf.layers.conv2d(self.X_placeholder, 64, [7, 7], strides=[2, 2], padding=\"SAME\", activation=tf.nn.relu)\n",
    "        pool_1 = tf.layers.max_pooling2d(conv_1, [3, 3], [2, 2], \"SAME\")\n",
    "        norm_1 = tf.layers.batch_normalization(pool_1, training=self.is_training_placeholder)\n",
    "        conv_2 = tf.layers.conv2d(norm_1, 192, [3, 3], strides=[1, 1], padding=\"SAME\", activation=tf.nn.relu)\n",
    "        pool_2 = tf.layers.max_pooling2d(conv_2, [3, 3], [2, 2], \"SAME\")\n",
    "        norm_2 = tf.layers.batch_normalization(pool_2, training=self.is_training_placeholder)\n",
    "\n",
    "        inception_1a = self.inception(norm_2, 64, 64, 64, 64, 96, \"AVG\", 32, False)\n",
    "        inception_1b = self.inception(inception_1a, 64, 64, 96, 64, 96, \"AVG\", 64, False)\n",
    "        inception_1c = self.inception(inception_1b, 0, 128, 160, 64, 96, \"MAX\", 0, True)\n",
    "        inception_2a = self.inception(inception_1c, 224, 64, 96, 96, 128, \"AVG\", 128, False)\n",
    "        inception_2b = self.inception(inception_2a, 192, 96, 128, 96, 128, \"AVG\", 128, False)\n",
    "        inception_2c = self.inception(inception_2b, 160, 128, 160, 128, 160, \"AVG\", 128, False)\n",
    "        inception_2d = self.inception(inception_2c, 96, 128, 192, 160, 192, \"AVG\", 128, False)\n",
    "        inception_2e = self.inception(inception_2d, 0, 128, 192, 192, 256, \"MAX\", 0, True)\n",
    "        inception_3a = self.inception(inception_2e, 352, 192, 320, 160, 224, \"AVG\", 128, False)\n",
    "        inception_3b = self.inception(inception_3a, 352, 192, 320, 192, 224, \"MAX\", 128, False)\n",
    "\n",
    "        # The following pooling size is changed from the original paper due to different starting image sizes\n",
    "        pool_3 = tf.nn.pool(inception_3b, [8, 8], \"AVG\", \"VALID\", strides=[1, 1])\n",
    "        if self.config.keep_prob < 1.0:\n",
    "            pool_3 = tf.nn.dropout(pool_3, self.config.keep_prob)\n",
    "        y_out = tf.layers.dense(pool_3, 20)\n",
    "        return y_out[:, 0, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n",
      "Batch 100/398 of epoch 1 finished in 89.556353 seconds\n",
      "Batch 200/398 of epoch 1 finished in 84.762005 seconds\n",
      "Batch 300/398 of epoch 1 finished in 84.046106 seconds\n",
      "Epoch 1 training finished in 342.624720 seconds\n",
      "train accuracy:27.2%\n",
      "val accuracy:27.6%\n",
      "Epoch 1 evaluation finished in 179.340479 seconds\n",
      "---------------------------------------------------------\n",
      "Batch 100/398 of epoch 2 finished in 84.674983 seconds\n",
      "Batch 200/398 of epoch 2 finished in 84.566512 seconds\n",
      "Batch 300/398 of epoch 2 finished in 84.620688 seconds\n",
      "Epoch 2 training finished in 336.421566 seconds\n",
      "train accuracy:44.9%\n",
      "val accuracy:43.5%\n",
      "Epoch 2 evaluation finished in 169.424043 seconds\n",
      "---------------------------------------------------------\n",
      "Batch 100/398 of epoch 3 finished in 84.345246 seconds\n",
      "Batch 200/398 of epoch 3 finished in 84.181527 seconds\n",
      "Batch 300/398 of epoch 3 finished in 83.834562 seconds\n",
      "Epoch 3 training finished in 334.315796 seconds\n",
      "train accuracy:43.3%\n",
      "val accuracy:41.4%\n",
      "Epoch 3 evaluation finished in 169.756382 seconds\n",
      "---------------------------------------------------------\n",
      "Batch 100/398 of epoch 4 finished in 84.168792 seconds\n",
      "Batch 200/398 of epoch 4 finished in 84.022023 seconds\n",
      "Batch 300/398 of epoch 4 finished in 84.166997 seconds\n",
      "Epoch 4 training finished in 334.583207 seconds\n",
      "train accuracy:48.5%\n",
      "val accuracy:47.0%\n",
      "Epoch 4 evaluation finished in 169.045571 seconds\n",
      "---------------------------------------------------------\n",
      "Batch 100/398 of epoch 5 finished in 83.877655 seconds\n",
      "Batch 200/398 of epoch 5 finished in 83.834566 seconds\n",
      "Batch 300/398 of epoch 5 finished in 83.729561 seconds\n",
      "Epoch 5 training finished in 333.250211 seconds\n",
      "train accuracy:45.9%\n",
      "val accuracy:44.3%\n",
      "Epoch 5 evaluation finished in 169.249887 seconds\n"
     ]
    }
   ],
   "source": [
    "from config import ModelConfig, TrainConfig\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "model_config = ModelConfig(eval_batch_size=512)\n",
    "train_config = TrainConfig(print_every=100, num_epochs=5)\n",
    "model = GoogleNet(model_config)\n",
    "sess = tf.Session()\n",
    "model.train(data, sess, train_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
