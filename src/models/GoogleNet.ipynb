{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import util\n",
    "\n",
    "address = '../../data/'\n",
    "file_names = {}\n",
    "file_names['images'] = 'small_data.npy'\n",
    "file_names['subs'] = 'small_subredditlabels'\n",
    "file_names['dict'] = 'small_subredditIndex'\n",
    "file_names['nsfw'] = 'small_nsfwlabels'\n",
    "data, dictionary = util.import_dataset(address, file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 128, 128, 3)\n",
      "(100, 128, 128, 3)\n",
      "(100, 128, 128, 3)\n",
      "(800,)\n",
      "(100,)\n",
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "print(data.X_train.shape)\n",
    "print(data.X_val.shape)\n",
    "print(data.X_test.shape)\n",
    "print(data.y_train.shape)\n",
    "print(data.y_val.shape)\n",
    "print(data.y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from model import Model, lazy_property\n",
    "\n",
    "class GoogleNet(Model):\n",
    "    def __init__(self, model_config):\n",
    "        Model.__init__(self, model_config)\n",
    "    \n",
    "    def inception(self, input_layer, num_1x1, num_3x3_reduce, num_3x3, num_double_3x3_reduce, num_double_3x3, \n",
    "                  pool_type, proj_size, strided):\n",
    "        strides = [2, 2] if strided else [1, 1]  # last layer strides (before concatenation)\n",
    "\n",
    "        if num_1x1 > 0:\n",
    "            inception_1_conv1 = tf.layers.conv2d(input_layer, num_1x1, [1, 1], strides=strides, padding=\"SAME\")\n",
    "            inception_1_bn1 = tf.layers.batch_normalization(inception_1_conv1, training=self.is_training_placeholder)\n",
    "            inception_1 = tf.nn.relu(inception_1_bn1)\n",
    "\n",
    "        inception_2_conv1 = tf.layers.conv2d(input_layer, num_3x3_reduce, [1, 1], strides=[1, 1], padding=\"SAME\", activation=tf.nn.relu)\n",
    "        inception_2_conv2 = tf.layers.conv2d(inception_2_conv1, num_3x3, [3, 3], strides=strides, padding=\"SAME\")\n",
    "        inception_2_bn1 = tf.layers.batch_normalization(inception_2_conv2, training=self.is_training_placeholder)\n",
    "        inception_2 = tf.nn.relu(inception_2_bn1)\n",
    "\n",
    "        inception_3_conv1 = tf.layers.conv2d(input_layer, 64, [1, 1], strides=[1, 1], padding=\"SAME\", activation=tf.nn.relu)\n",
    "        inception_3_conv2 = tf.layers.conv2d(inception_3_conv1, 96, [3, 3], strides=[1, 1], padding=\"SAME\", activation=tf.nn.relu)\n",
    "        inception_3_conv3 = tf.layers.conv2d(inception_3_conv2, 96, [3, 3], strides=strides, padding=\"SAME\")\n",
    "        inception_3_bn1 = tf.layers.batch_normalization(inception_3_conv3, training=self.is_training_placeholder)\n",
    "        inception_3 = tf.nn.relu(inception_3_bn1)\n",
    "\n",
    "        inception_4_pool1 = tf.nn.pool(input_layer, [3, 3], pool_type, \"SAME\", strides=strides)\n",
    "        if proj_size == 0:\n",
    "            inception_4 = tf.nn.relu(inception_4_pool1)  # pass through layer if proj_size is 0\n",
    "        else:\n",
    "            inception_4_conv1 = tf.layers.conv2d(inception_4_pool1, proj_size, [1, 1], padding=\"SAME\")\n",
    "            inception_4_bn1 = tf.layers.batch_normalization(inception_4_conv1, training=self.is_training_placeholder)\n",
    "            inception_4 = tf.nn.relu(inception_4_bn1)\n",
    "\n",
    "        if num_1x1 > 0:\n",
    "            inception_out = tf.concat([inception_1, inception_2, inception_3, inception_4], -1)\n",
    "        else:\n",
    "            inception_out = tf.concat([inception_2, inception_3, inception_4], -1)\n",
    "        return inception_out\n",
    "    \n",
    "    @lazy_property\n",
    "    def prediction(self):\n",
    "        conv_1 = tf.layers.conv2d(self.X_placeholder, 64, [7, 7], strides=[2, 2], padding=\"SAME\", activation=tf.nn.relu)\n",
    "        pool_1 = tf.layers.max_pooling2d(conv_1, [3, 3], [2, 2], \"SAME\")\n",
    "        norm_1 = tf.layers.batch_normalization(pool_1, training=self.is_training_placeholder)\n",
    "        conv_2 = tf.layers.conv2d(norm_1, 192, [3, 3], strides=[1, 1], padding=\"SAME\", activation=tf.nn.relu)\n",
    "        pool_2 = tf.layers.max_pooling2d(conv_2, [3, 3], [2, 2], \"SAME\")\n",
    "        norm_2 = tf.layers.batch_normalization(pool_2, training=self.is_training_placeholder)\n",
    "\n",
    "        inception_1a = self.inception(norm_2, 64, 64, 64, 64, 96, \"AVG\", 32, False)\n",
    "        inception_1b = self.inception(inception_1a, 64, 64, 96, 64, 96, \"AVG\", 64, False)\n",
    "        inception_1c = self.inception(inception_1b, 0, 128, 160, 64, 96, \"MAX\", 0, True)\n",
    "        inception_2a = self.inception(inception_1c, 224, 64, 96, 96, 128, \"AVG\", 128, False)\n",
    "        inception_2b = self.inception(inception_2a, 192, 96, 128, 96, 128, \"AVG\", 128, False)\n",
    "        inception_2c = self.inception(inception_2b, 160, 128, 160, 128, 160, \"AVG\", 128, False)\n",
    "        inception_2d = self.inception(inception_2c, 96, 128, 192, 160, 192, \"AVG\", 128, False)\n",
    "        inception_2e = self.inception(inception_2d, 0, 128, 192, 192, 256, \"MAX\", 0, True)\n",
    "        inception_3a = self.inception(inception_2e, 352, 192, 320, 160, 224, \"AVG\", 128, False)\n",
    "        inception_3b = self.inception(inception_3a, 352, 192, 320, 192, 224, \"MAX\", 128, False)\n",
    "\n",
    "        # The following pooling size is changed from the original paper due to different starting image sizes\n",
    "        pool_3 = tf.nn.pool(inception_3b, [4, 4], \"AVG\", \"VALID\", strides=[1, 1])\n",
    "        if self.config.keep_prob < 1.0:\n",
    "            pool_3 = tf.nn.dropout(pool_3, self.config.keep_prob)\n",
    "        y_out = tf.layers.dense(pool_3, 20)\n",
    "        return y_out[:, 0, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n",
      "Batch 1/13 of epoch 1 finished in 3.891214 seconds\n",
      "Batch 2/13 of epoch 1 finished in 0.304758 seconds\n",
      "Batch 3/13 of epoch 1 finished in 0.289159 seconds\n",
      "Batch 4/13 of epoch 1 finished in 0.283229 seconds\n",
      "Batch 5/13 of epoch 1 finished in 0.290190 seconds\n",
      "Batch 6/13 of epoch 1 finished in 0.287888 seconds\n",
      "Batch 7/13 of epoch 1 finished in 0.285074 seconds\n",
      "Batch 8/13 of epoch 1 finished in 0.283756 seconds\n",
      "Batch 9/13 of epoch 1 finished in 0.288406 seconds\n",
      "Batch 10/13 of epoch 1 finished in 0.283701 seconds\n",
      "Batch 11/13 of epoch 1 finished in 0.284885 seconds\n",
      "Batch 12/13 of epoch 1 finished in 0.288972 seconds\n",
      "Batch 13/13 of epoch 1 finished in 0.191748 seconds\n",
      "Epoch 1 training finished in 7.253471 seconds\n",
      "train accuracy:8.4%\n",
      "val accuracy:7.0%\n",
      "Epoch 1 evaluation finished in 7.253471 seconds\n",
      "---------------------------------------------------------\n",
      "Batch 1/13 of epoch 2 finished in 0.289644 seconds\n",
      "Batch 2/13 of epoch 2 finished in 0.292535 seconds\n",
      "Batch 3/13 of epoch 2 finished in 0.290699 seconds\n",
      "Batch 4/13 of epoch 2 finished in 0.291950 seconds\n",
      "Batch 5/13 of epoch 2 finished in 0.288009 seconds\n",
      "Batch 6/13 of epoch 2 finished in 0.292772 seconds\n",
      "Batch 7/13 of epoch 2 finished in 0.286518 seconds\n",
      "Batch 8/13 of epoch 2 finished in 0.289424 seconds\n",
      "Batch 9/13 of epoch 2 finished in 0.287465 seconds\n",
      "Batch 10/13 of epoch 2 finished in 0.284011 seconds\n",
      "Batch 11/13 of epoch 2 finished in 0.283985 seconds\n",
      "Batch 12/13 of epoch 2 finished in 0.286400 seconds\n",
      "Batch 13/13 of epoch 2 finished in 0.187521 seconds\n",
      "Epoch 2 training finished in 3.651542 seconds\n",
      "train accuracy:11.4%\n",
      "val accuracy:10.0%\n",
      "Epoch 2 evaluation finished in 3.651542 seconds\n"
     ]
    }
   ],
   "source": [
    "from config import ModelConfig, TrainConfig\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "model_config = ModelConfig()\n",
    "train_config = TrainConfig(print_every=1, num_epochs=2)\n",
    "model = GoogleNet(model_config)\n",
    "sess = tf.Session()\n",
    "model.train(data, sess, train_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
