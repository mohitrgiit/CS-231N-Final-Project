{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import util\n",
    "\n",
    "address = '../../data/'\n",
    "file_names = {}\n",
    "file_names['images'] = 'small_data.npy'\n",
    "file_names['subs'] = 'small_subredditlabels'\n",
    "file_names['dict'] = 'small_subredditIndex'\n",
    "data, dictionary = util.import_dataset(address, file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 128, 128, 3)\n",
      "(100, 128, 128, 3)\n",
      "(100, 128, 128, 3)\n",
      "(800,)\n",
      "(100,)\n",
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "print(data.X_train.shape)\n",
    "print(data.X_val.shape)\n",
    "print(data.X_test.shape)\n",
    "print(data.y_train.shape)\n",
    "print(data.y_val.shape)\n",
    "print(data.y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from model import Model, lazy_property\n",
    "\n",
    "class GoogleNet(Model):\n",
    "    def __init__(self, model_config):\n",
    "        Model.__init__(self, model_config)\n",
    "    \n",
    "    def inception(self, input_layer, num_1x1, num_3x3_reduce, num_3x3, num_double_3x3_reduce, num_double_3x3, \n",
    "                  pool_type, proj_size, strided):\n",
    "        strides = [2, 2] if strided else [1, 1]  # last layer strides (before concatenation)\n",
    "\n",
    "        if num_1x1 > 0:\n",
    "            inception_1_conv1 = tf.layers.conv2d(input_layer, num_1x1, [1, 1], strides=strides, padding=\"SAME\")\n",
    "            inception_1_bn1 = tf.layers.batch_normalization(inception_1_conv1, training=self.is_training_placeholder)\n",
    "            inception_1 = tf.nn.relu(inception_1_bn1)\n",
    "\n",
    "        inception_2_conv1 = tf.layers.conv2d(input_layer, num_3x3_reduce, [1, 1], strides=[1, 1], padding=\"SAME\", activation=tf.nn.relu)\n",
    "        inception_2_conv2 = tf.layers.conv2d(inception_2_conv1, num_3x3, [3, 3], strides=strides, padding=\"SAME\")\n",
    "        inception_2_bn1 = tf.layers.batch_normalization(inception_2_conv2, training=self.is_training_placeholder)\n",
    "        inception_2 = tf.nn.relu(inception_2_bn1)\n",
    "\n",
    "        inception_3_conv1 = tf.layers.conv2d(input_layer, 64, [1, 1], strides=[1, 1], padding=\"SAME\", activation=tf.nn.relu)\n",
    "        inception_3_conv2 = tf.layers.conv2d(inception_3_conv1, 96, [3, 3], strides=[1, 1], padding=\"SAME\", activation=tf.nn.relu)\n",
    "        inception_3_conv3 = tf.layers.conv2d(inception_3_conv2, 96, [3, 3], strides=strides, padding=\"SAME\")\n",
    "        inception_3_bn1 = tf.layers.batch_normalization(inception_3_conv3, training=self.is_training_placeholder)\n",
    "        inception_3 = tf.nn.relu(inception_3_bn1)\n",
    "\n",
    "        inception_4_pool1 = tf.nn.pool(input_layer, [3, 3], pool_type, \"SAME\", strides=strides)\n",
    "        if proj_size == 0:\n",
    "            inception_4 = tf.nn.relu(inception_4_pool1)  # pass through layer if proj_size is 0\n",
    "        else:\n",
    "            inception_4_conv1 = tf.layers.conv2d(inception_4_pool1, proj_size, [1, 1], padding=\"SAME\")\n",
    "            inception_4_bn1 = tf.layers.batch_normalization(inception_4_conv1, training=self.is_training_placeholder)\n",
    "            inception_4 = tf.nn.relu(inception_4_bn1)\n",
    "\n",
    "        if num_1x1 > 0:\n",
    "            inception_out = tf.concat([inception_1, inception_2, inception_3, inception_4], -1)\n",
    "        else:\n",
    "            inception_out = tf.concat([inception_2, inception_3, inception_4], -1)\n",
    "        return inception_out\n",
    "    \n",
    "    @lazy_property\n",
    "    def prediction(self):\n",
    "        conv_1 = tf.layers.conv2d(self.X_placeholder, 64, [7, 7], strides=[2, 2], padding=\"SAME\", activation=tf.nn.relu)\n",
    "        pool_1 = tf.layers.max_pooling2d(conv_1, [3, 3], [2, 2], \"SAME\")\n",
    "        norm_1 = tf.layers.batch_normalization(pool_1, training=self.is_training_placeholder)\n",
    "        conv_2 = tf.layers.conv2d(norm_1, 192, [3, 3], strides=[1, 1], padding=\"SAME\", activation=tf.nn.relu)\n",
    "        pool_2 = tf.layers.max_pooling2d(conv_2, [3, 3], [2, 2], \"SAME\")\n",
    "        norm_2 = tf.layers.batch_normalization(pool_2, training=self.is_training_placeholder)\n",
    "\n",
    "        inception_1a = self.inception(norm_2, 64, 64, 64, 64, 96, \"AVG\", 32, False)\n",
    "        inception_1b = self.inception(inception_1a, 64, 64, 96, 64, 96, \"AVG\", 64, False)\n",
    "        inception_1c = self.inception(inception_1b, 0, 128, 160, 64, 96, \"MAX\", 0, True)\n",
    "        inception_2a = self.inception(inception_1c, 224, 64, 96, 96, 128, \"AVG\", 128, False)\n",
    "        inception_2b = self.inception(inception_2a, 192, 96, 128, 96, 128, \"AVG\", 128, False)\n",
    "        inception_2c = self.inception(inception_2b, 160, 128, 160, 128, 160, \"AVG\", 128, False)\n",
    "        inception_2d = self.inception(inception_2c, 96, 128, 192, 160, 192, \"AVG\", 128, False)\n",
    "        inception_2e = self.inception(inception_2d, 0, 128, 192, 192, 256, \"MAX\", 0, True)\n",
    "        inception_3a = self.inception(inception_2e, 352, 192, 320, 160, 224, \"AVG\", 128, False)\n",
    "        inception_3b = self.inception(inception_3a, 352, 192, 320, 192, 224, \"MAX\", 128, False)\n",
    "\n",
    "        # The following pooling size is changed from the original paper due to different starting image sizes\n",
    "        pool_3 = tf.nn.pool(inception_3b, [4, 4], \"AVG\", \"VALID\", strides=[1, 1])\n",
    "        if self.config.keep_prob < 1.0:\n",
    "            pool_3 = tf.nn.dropout(pool_3, self.config.keep_prob)\n",
    "        y_out = tf.layers.dense(pool_3, 20)\n",
    "        return y_out[:, 0, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1/12 of epoch 1 finished in 3.728922 seconds\n",
      "Batch 2/12 of epoch 1 finished in 0.292163 seconds\n",
      "Batch 3/12 of epoch 1 finished in 0.286211 seconds\n",
      "Batch 4/12 of epoch 1 finished in 0.285299 seconds\n",
      "Batch 5/12 of epoch 1 finished in 0.284053 seconds\n",
      "Batch 6/12 of epoch 1 finished in 0.286243 seconds\n",
      "Batch 7/12 of epoch 1 finished in 0.285886 seconds\n",
      "Batch 8/12 of epoch 1 finished in 0.281673 seconds\n",
      "Batch 9/12 of epoch 1 finished in 0.284856 seconds\n",
      "Batch 10/12 of epoch 1 finished in 0.285193 seconds\n",
      "Batch 11/12 of epoch 1 finished in 0.287623 seconds\n",
      "Batch 12/12 of epoch 1 finished in 0.287062 seconds\n",
      "Batch 13/12 of epoch 1 finished in 0.345665 seconds\n",
      "Epoch 1 finished in 7.221401 seconds\n",
      "Epoch: 1, Training Accuracy 9.6%, Vallidation Accuracy:9.0%\n",
      "Batch 1/12 of epoch 2 finished in 0.287828 seconds\n",
      "Batch 2/12 of epoch 2 finished in 0.284744 seconds\n",
      "Batch 3/12 of epoch 2 finished in 0.283657 seconds\n",
      "Batch 4/12 of epoch 2 finished in 0.290690 seconds\n",
      "Batch 5/12 of epoch 2 finished in 0.292082 seconds\n",
      "Batch 6/12 of epoch 2 finished in 0.289078 seconds\n",
      "Batch 7/12 of epoch 2 finished in 0.290760 seconds\n",
      "Batch 8/12 of epoch 2 finished in 0.291295 seconds\n",
      "Batch 9/12 of epoch 2 finished in 0.289736 seconds\n",
      "Batch 10/12 of epoch 2 finished in 0.292009 seconds\n",
      "Batch 11/12 of epoch 2 finished in 0.289680 seconds\n",
      "Batch 12/12 of epoch 2 finished in 0.284350 seconds\n",
      "Batch 13/12 of epoch 2 finished in 0.187104 seconds\n",
      "Epoch 2 finished in 3.653786 seconds\n",
      "Epoch: 2, Training Accuracy 7.1%, Vallidation Accuracy:9.0%\n",
      "Batch 1/12 of epoch 3 finished in 0.285397 seconds\n",
      "Batch 2/12 of epoch 3 finished in 0.282604 seconds\n",
      "Batch 3/12 of epoch 3 finished in 0.283100 seconds\n",
      "Batch 4/12 of epoch 3 finished in 0.283700 seconds\n",
      "Batch 5/12 of epoch 3 finished in 0.288042 seconds\n",
      "Batch 6/12 of epoch 3 finished in 0.287181 seconds\n",
      "Batch 7/12 of epoch 3 finished in 0.282208 seconds\n",
      "Batch 8/12 of epoch 3 finished in 0.287440 seconds\n",
      "Batch 9/12 of epoch 3 finished in 0.287177 seconds\n",
      "Batch 10/12 of epoch 3 finished in 0.287328 seconds\n",
      "Batch 11/12 of epoch 3 finished in 0.291045 seconds\n",
      "Batch 12/12 of epoch 3 finished in 0.287013 seconds\n",
      "Batch 13/12 of epoch 3 finished in 0.182864 seconds\n",
      "Epoch 3 finished in 3.615689 seconds\n",
      "Epoch: 3, Training Accuracy 7.1%, Vallidation Accuracy:9.0%\n",
      "Batch 1/12 of epoch 4 finished in 0.287637 seconds\n",
      "Batch 2/12 of epoch 4 finished in 0.287998 seconds\n",
      "Batch 3/12 of epoch 4 finished in 0.288215 seconds\n",
      "Batch 4/12 of epoch 4 finished in 0.283397 seconds\n",
      "Batch 5/12 of epoch 4 finished in 0.286910 seconds\n",
      "Batch 6/12 of epoch 4 finished in 0.285847 seconds\n",
      "Batch 7/12 of epoch 4 finished in 0.285571 seconds\n",
      "Batch 8/12 of epoch 4 finished in 0.285526 seconds\n",
      "Batch 9/12 of epoch 4 finished in 0.287422 seconds\n",
      "Batch 10/12 of epoch 4 finished in 0.288371 seconds\n",
      "Batch 11/12 of epoch 4 finished in 0.287439 seconds\n",
      "Batch 12/12 of epoch 4 finished in 0.288516 seconds\n",
      "Batch 13/12 of epoch 4 finished in 0.188258 seconds\n",
      "Epoch 4 finished in 3.631869 seconds\n",
      "Epoch: 4, Training Accuracy 7.4%, Vallidation Accuracy:9.0%\n",
      "Batch 1/12 of epoch 5 finished in 0.286733 seconds\n",
      "Batch 2/12 of epoch 5 finished in 0.287710 seconds\n",
      "Batch 3/12 of epoch 5 finished in 0.286777 seconds\n",
      "Batch 4/12 of epoch 5 finished in 0.287869 seconds\n",
      "Batch 5/12 of epoch 5 finished in 0.285944 seconds\n",
      "Batch 6/12 of epoch 5 finished in 0.287100 seconds\n",
      "Batch 7/12 of epoch 5 finished in 0.290744 seconds\n",
      "Batch 8/12 of epoch 5 finished in 0.285234 seconds\n",
      "Batch 9/12 of epoch 5 finished in 0.284331 seconds\n",
      "Batch 10/12 of epoch 5 finished in 0.287854 seconds\n",
      "Batch 11/12 of epoch 5 finished in 0.286668 seconds\n",
      "Batch 12/12 of epoch 5 finished in 0.285866 seconds\n",
      "Batch 13/12 of epoch 5 finished in 0.183904 seconds\n",
      "Epoch 5 finished in 3.627273 seconds\n",
      "Epoch: 5, Training Accuracy 8.1%, Vallidation Accuracy:10.0%\n",
      "Batch 1/12 of epoch 6 finished in 0.287574 seconds\n",
      "Batch 2/12 of epoch 6 finished in 0.287721 seconds\n",
      "Batch 3/12 of epoch 6 finished in 0.284552 seconds\n",
      "Batch 4/12 of epoch 6 finished in 0.285117 seconds\n",
      "Batch 5/12 of epoch 6 finished in 0.286417 seconds\n",
      "Batch 6/12 of epoch 6 finished in 0.287643 seconds\n",
      "Batch 7/12 of epoch 6 finished in 0.284566 seconds\n",
      "Batch 8/12 of epoch 6 finished in 0.287718 seconds\n",
      "Batch 9/12 of epoch 6 finished in 0.282288 seconds\n",
      "Batch 10/12 of epoch 6 finished in 0.279391 seconds\n",
      "Batch 11/12 of epoch 6 finished in 0.284348 seconds\n",
      "Batch 12/12 of epoch 6 finished in 0.286473 seconds\n",
      "Batch 13/12 of epoch 6 finished in 0.184553 seconds\n",
      "Epoch 6 finished in 3.608846 seconds\n",
      "Epoch: 6, Training Accuracy 10.1%, Vallidation Accuracy:12.0%\n",
      "Batch 1/12 of epoch 7 finished in 0.284066 seconds\n",
      "Batch 2/12 of epoch 7 finished in 0.284975 seconds\n",
      "Batch 3/12 of epoch 7 finished in 0.288081 seconds\n",
      "Batch 4/12 of epoch 7 finished in 0.290755 seconds\n",
      "Batch 5/12 of epoch 7 finished in 0.288665 seconds\n",
      "Batch 6/12 of epoch 7 finished in 0.284767 seconds\n",
      "Batch 7/12 of epoch 7 finished in 0.282577 seconds\n",
      "Batch 8/12 of epoch 7 finished in 0.285980 seconds\n",
      "Batch 9/12 of epoch 7 finished in 0.286466 seconds\n",
      "Batch 10/12 of epoch 7 finished in 0.284483 seconds\n",
      "Batch 11/12 of epoch 7 finished in 0.283829 seconds\n",
      "Batch 12/12 of epoch 7 finished in 0.286449 seconds\n",
      "Batch 13/12 of epoch 7 finished in 0.186718 seconds\n",
      "Epoch 7 finished in 3.618360 seconds\n",
      "Epoch: 7, Training Accuracy 12.1%, Vallidation Accuracy:13.0%\n",
      "Batch 1/12 of epoch 8 finished in 0.287609 seconds\n",
      "Batch 2/12 of epoch 8 finished in 0.292225 seconds\n",
      "Batch 3/12 of epoch 8 finished in 0.282900 seconds\n",
      "Batch 4/12 of epoch 8 finished in 0.287540 seconds\n",
      "Batch 5/12 of epoch 8 finished in 0.287020 seconds\n",
      "Batch 6/12 of epoch 8 finished in 0.284082 seconds\n",
      "Batch 7/12 of epoch 8 finished in 0.286756 seconds\n",
      "Batch 8/12 of epoch 8 finished in 0.281989 seconds\n",
      "Batch 9/12 of epoch 8 finished in 0.285017 seconds\n",
      "Batch 10/12 of epoch 8 finished in 0.282594 seconds\n",
      "Batch 11/12 of epoch 8 finished in 0.282966 seconds\n",
      "Batch 12/12 of epoch 8 finished in 0.281766 seconds\n",
      "Batch 13/12 of epoch 8 finished in 0.184119 seconds\n",
      "Epoch 8 finished in 3.607193 seconds\n",
      "Epoch: 8, Training Accuracy 10.9%, Vallidation Accuracy:13.0%\n",
      "Batch 1/12 of epoch 9 finished in 0.282339 seconds\n",
      "Batch 2/12 of epoch 9 finished in 0.284142 seconds\n",
      "Batch 3/12 of epoch 9 finished in 0.285107 seconds\n",
      "Batch 4/12 of epoch 9 finished in 0.280693 seconds\n",
      "Batch 5/12 of epoch 9 finished in 0.281239 seconds\n",
      "Batch 6/12 of epoch 9 finished in 0.283464 seconds\n",
      "Batch 7/12 of epoch 9 finished in 0.286183 seconds\n",
      "Batch 8/12 of epoch 9 finished in 0.288677 seconds\n",
      "Batch 9/12 of epoch 9 finished in 0.290624 seconds\n",
      "Batch 10/12 of epoch 9 finished in 0.288101 seconds\n",
      "Batch 11/12 of epoch 9 finished in 0.282073 seconds\n",
      "Batch 12/12 of epoch 9 finished in 0.288005 seconds\n",
      "Batch 13/12 of epoch 9 finished in 0.180136 seconds\n",
      "Epoch 9 finished in 3.601436 seconds\n",
      "Epoch: 9, Training Accuracy 7.8%, Vallidation Accuracy:9.0%\n",
      "Batch 1/12 of epoch 10 finished in 0.286437 seconds\n",
      "Batch 2/12 of epoch 10 finished in 0.285133 seconds\n",
      "Batch 3/12 of epoch 10 finished in 0.287584 seconds\n",
      "Batch 4/12 of epoch 10 finished in 0.286082 seconds\n",
      "Batch 5/12 of epoch 10 finished in 0.289352 seconds\n",
      "Batch 6/12 of epoch 10 finished in 0.282219 seconds\n",
      "Batch 7/12 of epoch 10 finished in 0.285696 seconds\n",
      "Batch 8/12 of epoch 10 finished in 0.284432 seconds\n",
      "Batch 9/12 of epoch 10 finished in 0.281431 seconds\n",
      "Batch 10/12 of epoch 10 finished in 0.286314 seconds\n",
      "Batch 11/12 of epoch 10 finished in 0.286885 seconds\n",
      "Batch 12/12 of epoch 10 finished in 0.290023 seconds\n",
      "Batch 13/12 of epoch 10 finished in 0.181376 seconds\n",
      "Epoch 10 finished in 3.613511 seconds\n",
      "Epoch:10, Training Accuracy 9.7%, Vallidation Accuracy:13.0%\n"
     ]
    }
   ],
   "source": [
    "from config import ModelConfig, TrainConfig\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "model_config = ModelConfig()\n",
    "train_config = TrainConfig(print_every=1)\n",
    "model = GoogleNet(model_config)\n",
    "sess = tf.Session()\n",
    "model.train(data, sess, train_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
