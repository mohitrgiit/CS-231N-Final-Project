{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import util\n",
    "\n",
    "address = '../../data/'\n",
    "file_names = {}\n",
    "file_names['images'] = 'small_data.npy'\n",
    "file_names['subs'] = 'small_subredditlabels'\n",
    "file_names['dict'] = 'small_subredditIndex'\n",
    "file_names['nsfw'] = 'small_nsfwlabels'\n",
    "data, dictionary = util.import_dataset(address, file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 128, 128, 3)\n",
      "(100, 128, 128, 3)\n",
      "(100, 128, 128, 3)\n",
      "(800,)\n",
      "(100,)\n",
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "print(data.X_train.shape)\n",
    "print(data.X_val.shape)\n",
    "print(data.X_test.shape)\n",
    "print(data.y_train.shape)\n",
    "print(data.y_val.shape)\n",
    "print(data.y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from model import Model, lazy_property\n",
    "\n",
    "class GoogleNet(Model):\n",
    "    def __init__(self, model_config):\n",
    "        Model.__init__(self, model_config)\n",
    "    \n",
    "    def inception(self, input_layer, num_1x1, num_3x3_reduce, num_3x3, num_double_3x3_reduce, num_double_3x3, \n",
    "                  pool_type, proj_size, strided):\n",
    "        strides = [2, 2] if strided else [1, 1]  # last layer strides (before concatenation)\n",
    "\n",
    "        if num_1x1 > 0:\n",
    "            inception_1_conv1 = tf.layers.conv2d(input_layer, num_1x1, [1, 1], strides=strides, padding=\"SAME\")\n",
    "            inception_1_bn1 = tf.layers.batch_normalization(inception_1_conv1, training=self.is_training_placeholder)\n",
    "            inception_1 = tf.nn.relu(inception_1_bn1)\n",
    "\n",
    "        inception_2_conv1 = tf.layers.conv2d(input_layer, num_3x3_reduce, [1, 1], strides=[1, 1], padding=\"SAME\", activation=tf.nn.relu)\n",
    "        inception_2_conv2 = tf.layers.conv2d(inception_2_conv1, num_3x3, [3, 3], strides=strides, padding=\"SAME\")\n",
    "        inception_2_bn1 = tf.layers.batch_normalization(inception_2_conv2, training=self.is_training_placeholder)\n",
    "        inception_2 = tf.nn.relu(inception_2_bn1)\n",
    "\n",
    "        inception_3_conv1 = tf.layers.conv2d(input_layer, 64, [1, 1], strides=[1, 1], padding=\"SAME\", activation=tf.nn.relu)\n",
    "        inception_3_conv2 = tf.layers.conv2d(inception_3_conv1, 96, [3, 3], strides=[1, 1], padding=\"SAME\", activation=tf.nn.relu)\n",
    "        inception_3_conv3 = tf.layers.conv2d(inception_3_conv2, 96, [3, 3], strides=strides, padding=\"SAME\")\n",
    "        inception_3_bn1 = tf.layers.batch_normalization(inception_3_conv3, training=self.is_training_placeholder)\n",
    "        inception_3 = tf.nn.relu(inception_3_bn1)\n",
    "\n",
    "        inception_4_pool1 = tf.nn.pool(input_layer, [3, 3], pool_type, \"SAME\", strides=strides)\n",
    "        if proj_size == 0:\n",
    "            inception_4 = tf.nn.relu(inception_4_pool1)  # pass through layer if proj_size is 0\n",
    "        else:\n",
    "            inception_4_conv1 = tf.layers.conv2d(inception_4_pool1, proj_size, [1, 1], padding=\"SAME\")\n",
    "            inception_4_bn1 = tf.layers.batch_normalization(inception_4_conv1, training=self.is_training_placeholder)\n",
    "            inception_4 = tf.nn.relu(inception_4_bn1)\n",
    "\n",
    "        if num_1x1 > 0:\n",
    "            inception_out = tf.concat([inception_1, inception_2, inception_3, inception_4], -1)\n",
    "        else:\n",
    "            inception_out = tf.concat([inception_2, inception_3, inception_4], -1)\n",
    "        return inception_out\n",
    "    \n",
    "    @lazy_property\n",
    "    def prediction(self):\n",
    "        conv_1 = tf.layers.conv2d(self.X_placeholder, 64, [7, 7], strides=[2, 2], padding=\"SAME\", activation=tf.nn.relu)\n",
    "        pool_1 = tf.layers.max_pooling2d(conv_1, [3, 3], [2, 2], \"SAME\")\n",
    "        norm_1 = tf.layers.batch_normalization(pool_1, training=self.is_training_placeholder)\n",
    "        conv_2 = tf.layers.conv2d(norm_1, 192, [3, 3], strides=[1, 1], padding=\"SAME\", activation=tf.nn.relu)\n",
    "        pool_2 = tf.layers.max_pooling2d(conv_2, [3, 3], [2, 2], \"SAME\")\n",
    "        norm_2 = tf.layers.batch_normalization(pool_2, training=self.is_training_placeholder)\n",
    "\n",
    "        inception_1a = self.inception(norm_2, 64, 64, 64, 64, 96, \"AVG\", 32, False)\n",
    "        inception_1b = self.inception(inception_1a, 64, 64, 96, 64, 96, \"AVG\", 64, False)\n",
    "        inception_1c = self.inception(inception_1b, 0, 128, 160, 64, 96, \"MAX\", 0, True)\n",
    "        inception_2a = self.inception(inception_1c, 224, 64, 96, 96, 128, \"AVG\", 128, False)\n",
    "        inception_2b = self.inception(inception_2a, 192, 96, 128, 96, 128, \"AVG\", 128, False)\n",
    "        inception_2c = self.inception(inception_2b, 160, 128, 160, 128, 160, \"AVG\", 128, False)\n",
    "        inception_2d = self.inception(inception_2c, 96, 128, 192, 160, 192, \"AVG\", 128, False)\n",
    "        inception_2e = self.inception(inception_2d, 0, 128, 192, 192, 256, \"MAX\", 0, True)\n",
    "        inception_3a = self.inception(inception_2e, 352, 192, 320, 160, 224, \"AVG\", 128, False)\n",
    "        inception_3b = self.inception(inception_3a, 352, 192, 320, 192, 224, \"MAX\", 128, False)\n",
    "\n",
    "        # The following pooling size is changed from the original paper due to different starting image sizes\n",
    "        pool_3 = tf.nn.pool(inception_3b, [4, 4], \"AVG\", \"VALID\", strides=[1, 1])\n",
    "        if self.config.keep_prob < 1.0:\n",
    "            pool_3 = tf.nn.dropout(pool_3, self.config.keep_prob)\n",
    "        y_out = tf.layers.dense(pool_3, 20)\n",
    "        return y_out[:, 0, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n",
      "Batch 1/13 of epoch 1 finished in 4.177517 seconds\n",
      "Batch 2/13 of epoch 1 finished in 0.305029 seconds\n",
      "Batch 3/13 of epoch 1 finished in 0.300214 seconds\n",
      "Batch 4/13 of epoch 1 finished in 0.292665 seconds\n",
      "Batch 5/13 of epoch 1 finished in 0.292057 seconds\n",
      "Batch 6/13 of epoch 1 finished in 0.293832 seconds\n",
      "Batch 7/13 of epoch 1 finished in 0.293571 seconds\n",
      "Batch 8/13 of epoch 1 finished in 0.293946 seconds\n",
      "Batch 9/13 of epoch 1 finished in 0.291217 seconds\n",
      "Batch 10/13 of epoch 1 finished in 0.290580 seconds\n",
      "Batch 11/13 of epoch 1 finished in 0.293666 seconds\n",
      "Batch 12/13 of epoch 1 finished in 0.292295 seconds\n",
      "Batch 13/13 of epoch 1 finished in 0.189416 seconds\n",
      "Epoch 1 training finished in 7.606733 seconds\n",
      "train accuracy:6.2%\n",
      "val accuracy:4.0%\n",
      "---------------------------------------------------------\n",
      "Batch 1/13 of epoch 2 finished in 0.295148 seconds\n",
      "Batch 2/13 of epoch 2 finished in 0.289791 seconds\n",
      "Batch 3/13 of epoch 2 finished in 0.292196 seconds\n",
      "Batch 4/13 of epoch 2 finished in 0.290969 seconds\n",
      "Batch 5/13 of epoch 2 finished in 0.293339 seconds\n",
      "Batch 6/13 of epoch 2 finished in 0.290412 seconds\n",
      "Batch 7/13 of epoch 2 finished in 0.294170 seconds\n",
      "Batch 8/13 of epoch 2 finished in 0.293388 seconds\n",
      "Batch 9/13 of epoch 2 finished in 0.292833 seconds\n",
      "Batch 10/13 of epoch 2 finished in 0.292941 seconds\n",
      "Batch 11/13 of epoch 2 finished in 0.292282 seconds\n",
      "Batch 12/13 of epoch 2 finished in 0.286774 seconds\n",
      "Batch 13/13 of epoch 2 finished in 0.186631 seconds\n",
      "Epoch 2 training finished in 3.691603 seconds\n",
      "train accuracy:12.7%\n",
      "val accuracy:11.0%\n",
      "---------------------------------------------------------\n",
      "Batch 1/13 of epoch 3 finished in 0.289034 seconds\n",
      "Batch 2/13 of epoch 3 finished in 0.292923 seconds\n",
      "Batch 3/13 of epoch 3 finished in 0.293054 seconds\n",
      "Batch 4/13 of epoch 3 finished in 0.291032 seconds\n",
      "Batch 5/13 of epoch 3 finished in 0.289956 seconds\n",
      "Batch 6/13 of epoch 3 finished in 0.290488 seconds\n",
      "Batch 7/13 of epoch 3 finished in 0.291164 seconds\n",
      "Batch 8/13 of epoch 3 finished in 0.292661 seconds\n",
      "Batch 9/13 of epoch 3 finished in 0.293700 seconds\n",
      "Batch 10/13 of epoch 3 finished in 0.290732 seconds\n",
      "Batch 11/13 of epoch 3 finished in 0.289905 seconds\n",
      "Batch 12/13 of epoch 3 finished in 0.292203 seconds\n",
      "Batch 13/13 of epoch 3 finished in 0.188813 seconds\n",
      "Epoch 3 training finished in 3.686407 seconds\n",
      "train accuracy:7.1%\n",
      "val accuracy:9.0%\n",
      "---------------------------------------------------------\n",
      "Batch 1/13 of epoch 4 finished in 0.288815 seconds\n",
      "Batch 2/13 of epoch 4 finished in 0.291264 seconds\n",
      "Batch 3/13 of epoch 4 finished in 0.288478 seconds\n",
      "Batch 4/13 of epoch 4 finished in 0.291176 seconds\n",
      "Batch 5/13 of epoch 4 finished in 0.293876 seconds\n",
      "Batch 6/13 of epoch 4 finished in 0.293940 seconds\n",
      "Batch 7/13 of epoch 4 finished in 0.291604 seconds\n",
      "Batch 8/13 of epoch 4 finished in 0.290852 seconds\n",
      "Batch 9/13 of epoch 4 finished in 0.291800 seconds\n",
      "Batch 10/13 of epoch 4 finished in 0.292480 seconds\n",
      "Batch 11/13 of epoch 4 finished in 0.288615 seconds\n",
      "Batch 12/13 of epoch 4 finished in 0.292830 seconds\n",
      "Batch 13/13 of epoch 4 finished in 0.192589 seconds\n",
      "Epoch 4 training finished in 3.688943 seconds\n",
      "train accuracy:7.9%\n",
      "val accuracy:10.0%\n",
      "---------------------------------------------------------\n",
      "Batch 1/13 of epoch 5 finished in 0.287113 seconds\n",
      "Batch 2/13 of epoch 5 finished in 0.292570 seconds\n",
      "Batch 3/13 of epoch 5 finished in 0.292070 seconds\n",
      "Batch 4/13 of epoch 5 finished in 0.292603 seconds\n",
      "Batch 5/13 of epoch 5 finished in 0.286739 seconds\n",
      "Batch 6/13 of epoch 5 finished in 0.293158 seconds\n",
      "Batch 7/13 of epoch 5 finished in 0.292503 seconds\n",
      "Batch 8/13 of epoch 5 finished in 0.287696 seconds\n",
      "Batch 9/13 of epoch 5 finished in 0.289736 seconds\n",
      "Batch 10/13 of epoch 5 finished in 0.289815 seconds\n",
      "Batch 11/13 of epoch 5 finished in 0.289960 seconds\n",
      "Batch 12/13 of epoch 5 finished in 0.289890 seconds\n",
      "Batch 13/13 of epoch 5 finished in 0.191448 seconds\n",
      "Epoch 5 training finished in 3.675971 seconds\n",
      "train accuracy:11.4%\n",
      "val accuracy:11.0%\n",
      "---------------------------------------------------------\n",
      "Batch 1/13 of epoch 6 finished in 0.295517 seconds\n",
      "Batch 2/13 of epoch 6 finished in 0.293834 seconds\n",
      "Batch 3/13 of epoch 6 finished in 0.291010 seconds\n",
      "Batch 4/13 of epoch 6 finished in 0.294069 seconds\n",
      "Batch 5/13 of epoch 6 finished in 0.290432 seconds\n",
      "Batch 6/13 of epoch 6 finished in 0.298541 seconds\n",
      "Batch 7/13 of epoch 6 finished in 0.293049 seconds\n",
      "Batch 8/13 of epoch 6 finished in 0.291403 seconds\n",
      "Batch 9/13 of epoch 6 finished in 0.294680 seconds\n",
      "Batch 10/13 of epoch 6 finished in 0.290923 seconds\n",
      "Batch 11/13 of epoch 6 finished in 0.294056 seconds\n",
      "Batch 12/13 of epoch 6 finished in 0.291047 seconds\n",
      "Batch 13/13 of epoch 6 finished in 0.189487 seconds\n",
      "Epoch 6 training finished in 3.708670 seconds\n",
      "train accuracy:8.6%\n",
      "val accuracy:9.0%\n",
      "---------------------------------------------------------\n",
      "Batch 1/13 of epoch 7 finished in 0.293769 seconds\n",
      "Batch 2/13 of epoch 7 finished in 0.293846 seconds\n",
      "Batch 3/13 of epoch 7 finished in 0.294580 seconds\n",
      "Batch 4/13 of epoch 7 finished in 0.290751 seconds\n",
      "Batch 5/13 of epoch 7 finished in 0.291526 seconds\n",
      "Batch 6/13 of epoch 7 finished in 0.293633 seconds\n",
      "Batch 7/13 of epoch 7 finished in 0.291639 seconds\n",
      "Batch 8/13 of epoch 7 finished in 0.290721 seconds\n",
      "Batch 9/13 of epoch 7 finished in 0.291321 seconds\n",
      "Batch 10/13 of epoch 7 finished in 0.291183 seconds\n",
      "Batch 11/13 of epoch 7 finished in 0.291907 seconds\n",
      "Batch 12/13 of epoch 7 finished in 0.290303 seconds\n",
      "Batch 13/13 of epoch 7 finished in 0.195757 seconds\n",
      "Epoch 7 training finished in 3.701642 seconds\n",
      "train accuracy:7.4%\n",
      "val accuracy:9.0%\n",
      "---------------------------------------------------------\n",
      "Batch 1/13 of epoch 8 finished in 0.290948 seconds\n",
      "Batch 2/13 of epoch 8 finished in 0.290535 seconds\n",
      "Batch 3/13 of epoch 8 finished in 0.290544 seconds\n",
      "Batch 4/13 of epoch 8 finished in 0.291299 seconds\n",
      "Batch 5/13 of epoch 8 finished in 0.295049 seconds\n",
      "Batch 6/13 of epoch 8 finished in 0.291404 seconds\n",
      "Batch 7/13 of epoch 8 finished in 0.292051 seconds\n",
      "Batch 8/13 of epoch 8 finished in 0.290021 seconds\n",
      "Batch 9/13 of epoch 8 finished in 0.293206 seconds\n",
      "Batch 10/13 of epoch 8 finished in 0.292687 seconds\n",
      "Batch 11/13 of epoch 8 finished in 0.290668 seconds\n",
      "Batch 12/13 of epoch 8 finished in 0.292670 seconds\n",
      "Batch 13/13 of epoch 8 finished in 0.189947 seconds\n",
      "Epoch 8 training finished in 3.691632 seconds\n",
      "train accuracy:9.0%\n",
      "val accuracy:9.0%\n",
      "---------------------------------------------------------\n",
      "Batch 1/13 of epoch 9 finished in 0.290702 seconds\n",
      "Batch 2/13 of epoch 9 finished in 0.288584 seconds\n",
      "Batch 3/13 of epoch 9 finished in 0.292070 seconds\n",
      "Batch 4/13 of epoch 9 finished in 0.293660 seconds\n",
      "Batch 5/13 of epoch 9 finished in 0.289911 seconds\n",
      "Batch 6/13 of epoch 9 finished in 0.290240 seconds\n",
      "Batch 7/13 of epoch 9 finished in 0.288126 seconds\n",
      "Batch 8/13 of epoch 9 finished in 0.290244 seconds\n",
      "Batch 9/13 of epoch 9 finished in 0.290132 seconds\n",
      "Batch 10/13 of epoch 9 finished in 0.287780 seconds\n",
      "Batch 11/13 of epoch 9 finished in 0.288764 seconds\n",
      "Batch 12/13 of epoch 9 finished in 0.291015 seconds\n",
      "Batch 13/13 of epoch 9 finished in 0.192375 seconds\n",
      "Epoch 9 training finished in 3.674128 seconds\n",
      "train accuracy:10.5%\n",
      "val accuracy:11.0%\n",
      "---------------------------------------------------------\n",
      "Batch 1/13 of epoch 10 finished in 0.290537 seconds\n",
      "Batch 2/13 of epoch 10 finished in 0.291942 seconds\n",
      "Batch 3/13 of epoch 10 finished in 0.289124 seconds\n",
      "Batch 4/13 of epoch 10 finished in 0.288532 seconds\n",
      "Batch 5/13 of epoch 10 finished in 0.285847 seconds\n",
      "Batch 6/13 of epoch 10 finished in 0.291674 seconds\n",
      "Batch 7/13 of epoch 10 finished in 0.291191 seconds\n",
      "Batch 8/13 of epoch 10 finished in 0.293269 seconds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-1c38ddb56bb8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGoogleNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0msess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/rhe/CS-231N-Final-Project/src/models/model.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, data, session, train_config)\u001b[0m\n\u001b[0;32m     96\u001b[0m                 \u001b[0mbatch_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mtrain_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminibatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m                 session.run(self.optimize, {self.X_placeholder:batch_X, \\\n\u001b[1;32m---> 98\u001b[1;33m                                             self.y_placeholder:batch_y,self.is_training_placeholder:True})\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m                 \u001b[1;31m# print run time, current batch, and current epoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/cs231n/myVE35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    765\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 767\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    768\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/cs231n/myVE35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    963\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 965\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    966\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/cs231n/myVE35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1013\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1015\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1016\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m/home/cs231n/myVE35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1020\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1021\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1022\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1023\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/cs231n/myVE35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1004\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1005\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from config import ModelConfig, TrainConfig\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "model_config = ModelConfig()\n",
    "train_config = TrainConfig(print_every=1, num_epochs=2)\n",
    "model = GoogleNet(model_config)\n",
    "sess = tf.Session()\n",
    "model.train(data, sess, train_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
