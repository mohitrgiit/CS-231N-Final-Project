{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from util import import_dataset\n",
    "\n",
    "address = '../../data/'\n",
    "file_names = {}\n",
    "file_names['images'] = 'full_data.npy'\n",
    "file_names['subs'] = 'full_subredditlabels'\n",
    "file_names['dict'] = 'full_subredditIndex'\n",
    "file_names['nsfw'] = 'full_nsfwlabels'\n",
    "data, dictionary = import_dataset(address, file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25450, 128, 128, 3)\n",
      "(3181, 128, 128, 3)\n",
      "(3182, 128, 128, 3)\n",
      "(25450,)\n",
      "(3181,)\n",
      "(3182,)\n"
     ]
    }
   ],
   "source": [
    "print(data.X_train.shape)\n",
    "print(data.X_val.shape)\n",
    "print(data.X_test.shape)\n",
    "print(data.y_train.shape)\n",
    "print(data.y_val.shape)\n",
    "print(data.y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n",
      "Batch 100/398 of epoch 1 finished in 33.316869 seconds\n",
      "Batch 200/398 of epoch 1 finished in 29.653357 seconds\n",
      "Batch 300/398 of epoch 1 finished in 29.701008 seconds\n",
      "Epoch 1 training finished in 121.799803 seconds\n",
      "train accuracy:94.8%\n",
      "val accuracy:94.8%\n",
      "Epoch 1 evaluation finished in 22.952360 seconds\n",
      "---------------------------------------------------------\n",
      "Batch 100/398 of epoch 2 finished in 29.581750 seconds\n",
      "Batch 200/398 of epoch 2 finished in 29.602077 seconds\n",
      "Batch 300/398 of epoch 2 finished in 29.638256 seconds\n",
      "Epoch 2 training finished in 117.849646 seconds\n",
      "train accuracy:95.1%\n",
      "val accuracy:94.8%\n",
      "Epoch 2 evaluation finished in 21.322258 seconds\n",
      "---------------------------------------------------------\n",
      "Batch 100/398 of epoch 3 finished in 29.522658 seconds\n",
      "Batch 200/398 of epoch 3 finished in 29.414610 seconds\n",
      "Batch 300/398 of epoch 3 finished in 29.271164 seconds\n",
      "Epoch 3 training finished in 116.902187 seconds\n",
      "train accuracy:95.6%\n",
      "val accuracy:94.7%\n",
      "Epoch 3 evaluation finished in 21.631083 seconds\n",
      "---------------------------------------------------------\n",
      "Batch 100/398 of epoch 4 finished in 29.520110 seconds\n",
      "Batch 200/398 of epoch 4 finished in 29.604463 seconds\n",
      "Batch 300/398 of epoch 4 finished in 29.589854 seconds\n",
      "Epoch 4 training finished in 117.770187 seconds\n",
      "train accuracy:96.1%\n",
      "val accuracy:95.2%\n",
      "Epoch 4 evaluation finished in 21.907669 seconds\n",
      "---------------------------------------------------------\n",
      "Batch 100/398 of epoch 5 finished in 29.502343 seconds\n",
      "Batch 200/398 of epoch 5 finished in 29.384635 seconds\n",
      "Batch 300/398 of epoch 5 finished in 29.532713 seconds\n",
      "Epoch 5 training finished in 117.436434 seconds\n",
      "train accuracy:96.7%\n",
      "val accuracy:95.1%\n",
      "Epoch 5 evaluation finished in 23.305612 seconds\n",
      "---------------------------------------------------------\n",
      "Batch 100/398 of epoch 6 finished in 29.910896 seconds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-b6c2c681cc22>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGoogleNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0msess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/rhe/CS-231N-Final-Project/src/models/model.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, data, session, train_config)\u001b[0m\n\u001b[0;32m    111\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'improper output string use \"subreddit\" or \"nsfw\"'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m                 session.run(self.optimize, {self.X_placeholder:batch_X, \\\n\u001b[1;32m--> 113\u001b[1;33m                                             self.y_placeholder:batch_y,self.is_training_placeholder:True})\n\u001b[0m\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m                 \u001b[1;31m# print run time, current batch, and current epoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/cs231n/myVE35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    765\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 767\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    768\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/cs231n/myVE35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    963\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 965\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    966\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/cs231n/myVE35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1013\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1015\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1016\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m/home/cs231n/myVE35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1020\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1021\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1022\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1023\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/cs231n/myVE35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1004\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1005\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from googlenet import GoogleNet\n",
    "from config import ModelConfig, TrainConfig\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "model_config = ModelConfig(eval_batch_size=3000, learning_rate=5e-5, output=\"nsfw\")\n",
    "train_config = TrainConfig(print_every=100, num_epochs=8, saver_address=r'../../saved_params/', \\\n",
    "    save_file_name = 'GoogleNet_nsfw_classification_1e-3_96', lr_decay=0.96)\n",
    "model = GoogleNet(model_config)\n",
    "sess = tf.Session()\n",
    "model.train(data, sess, train_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy:94.3%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(800.43861389160156, 0.94311762073368188)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval(data, sess, split=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from googlenet import GoogleNet\n",
    "from config import ModelConfig, TrainConfig\n",
    "import pickle\n",
    "\n",
    "# Reset Graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Create model instance\n",
    "model_config = ModelConfig()\n",
    "model = GoogleNet(model_config)\n",
    "\n",
    "# Load Saved Model\n",
    "sess = tf.Session()\n",
    "saver = tf.train.Saver()\n",
    "save_file = \"../../saved_params/GoogleNet_nsfw_classification\"\n",
    "saver.restore(sess, save_file) \n",
    "saved_history = pickle.load(open(save_file + \"_modelhist\", 'rb'))\n",
    "model.model_history = saved_history\n",
    "\n",
    "# Test Model Accuracy\n",
    "loss_train, acc_train = model.eval(data, sess, split='train')\n",
    "loss_val, acc_val = model.eval(data, sess, split = 'val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.plot_loss_acc(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get model predictions\n",
    "y_val_pred = sess.run(model.prediction, {model.X_placeholder: data.X_val, model.y_placeholder: data.y_val, \n",
    "                                            model.is_training_placeholder:False})\n",
    "\n",
    "y_val_pred = np.argmax(y_val_pred, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from util import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "classes = [\"sfw\", \"nsfw\"]\n",
    "cm = confusion_matrix(data.y_val, y_val_pred)\n",
    "plot_confusion_matrix(cm, classes, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import hyperopt as hpropt\n",
    "\n",
    "def objective(args):\n",
    "    model_config = ModelConfig(learning_rate=args['learning_rate'], sbrd_weight=args['sbrd_weight'], keep_prob=args['keep_prob'])\n",
    "    train_config = TrainConfig(num_epochs=args['num_epochs'], lr_decay=args['lr_decay'])\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    model = GoogleNet(model_config)\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    model.train(data, sess, train_config)\n",
    "    cost, accuracy_sbrd, accuracy_nsfw = model.eval(data, sess, \"val\")\n",
    "    \n",
    "    saveList = {\n",
    "        'accuracy_sbrd' : accuracy_sbrd,\n",
    "        'accuracy_nsfw' : accuracy_nsfw,\n",
    "        'cost' : cost,\n",
    "        'num_epochs' : args['num_epochs'],\n",
    "        'learning_rate' : args['learning_rate'],\n",
    "        'lr_decay' : args['lr_decay'],\n",
    "        'sbrd_weight' : args['sbrd_weight'],\n",
    "        'keep_prob' : args['keep_prob']\n",
    "    }    \n",
    "    pickle.dump(saveList, open(\"../../hprOpt/\" + str(accuracy_sbrd) + \"_\"  + str(accuracy_nsfw) + \"_\" + str(cost) + \".dat\", \"wb\"))\n",
    "    model.plot_loss_acc(data)\n",
    "    return cost\n",
    "\n",
    "def optimize(space, max_evals=50):\n",
    "    \n",
    "    space = {\n",
    "        'num_epochs' : hpropt.hp.randint('num_epochs', 20),\n",
    "        'learning_rate' : hpropt.hp.loguniform('learning_rate', -4, -1),\n",
    "        'lr_decay' : hpropt.hp.uniform('lr_decay', 0.9, 1.0),\n",
    "        'sbrd_weight' : hpropt.hp.uniform('sbrd_weight', 0.5, 1.0),\n",
    "        'keep_prob' : hpropt.hp.uniform('keep_prob', 0.3, 1.0)\n",
    "    }\n",
    "    \n",
    "    best = hpropt.fmin(objective, space, algo=hpropt.tpe.suggest, max_evals=max_evals)\n",
    "    print(best)\n",
    "    \n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'num_epochs' : 1,\n",
    "    'learning_rate' : hpropt.hp.loguniform('learning_rate', -4, -1),\n",
    "    'lr_decay' : hpropt.hp.uniform('lr_decay', 0.9, 1),\n",
    "    'sbrd_weight' : hpropt.hp.uniform('sbrd_weight', 0.5, 1)\n",
    "}\n",
    "optimize(space, 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
