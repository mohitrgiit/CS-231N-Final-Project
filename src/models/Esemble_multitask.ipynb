{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from util import import_dataset\n",
    "\n",
    "address = '../../data/'\n",
    "file_names = {}\n",
    "file_names['images'] = 'small_data.npy'\n",
    "file_names['subs'] = 'small_subredditlabels'\n",
    "file_names['dict'] = 'small_subredditIndex'\n",
    "file_names['nsfw'] = 'small_nsfwlabels'\n",
    "data, dictionary = import_dataset(address, file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 128, 128, 3)\n",
      "(100, 128, 128, 3)\n",
      "(100, 128, 128, 3)\n",
      "(800,)\n",
      "(100,)\n",
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "print(data.X_train.shape)\n",
    "print(data.X_val.shape)\n",
    "print(data.X_test.shape)\n",
    "print(data.y_train.shape)\n",
    "print(data.y_val.shape)\n",
    "print(data.y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Restore AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from alexnet import AlexNetMulticlass\n",
    "from config import ModelConfig, TrainConfig\n",
    "import pickle\n",
    "\n",
    "# Reset Graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Create model instance\n",
    "model_config = ModelConfig(eval_batch_size=3000)\n",
    "model = AlexNetMulticlass(model_config)\n",
    "\n",
    "# Load Saved Model\n",
    "sess = tf.Session()\n",
    "saver = tf.train.Saver()\n",
    "save_file = \"\"\n",
    "saver.restore(sess, save_file) \n",
    "saved_history = pickle.load(open(save_file + \"_modelhist\", 'rb'))\n",
    "model.model_history = saved_history\n",
    "\n",
    "# Test Model Accuracy\n",
    "loss_train, acc_sbrd_train, acc_nsfw_train = model.eval(data, sess, split='train')\n",
    "loss_val, acc_sbrd_val, ac_nsfw_val = model.eval(data, sess, split = 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get model predictions\n",
    "alex_sbrd_logits, alex_nsfw_logits = sess.run(model.prediction, {model.X_placeholder: data.X_val, \\\n",
    "                                                               model.y_sbrd_placeholder: data.y_val, \\\n",
    "                                                               model.y_nsfw_placeholder: data.y_val_2, \\\n",
    "                                                               model.is_training_placeholder:False})\n",
    "alex_sbrd_pred = np.argmax(alex_sbrd_logits, axis = 1)\n",
    "alex_nsfw_pred = np.argmax(alex_nsfw_logits, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Restore GoogleNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from googlenet import GoogleNetMulticlass\n",
    "\n",
    "# Reset Graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Create model instance\n",
    "model_config = ModelConfig(eval_batch_size=3000)\n",
    "model = GoogleNetMulticlass(model_config)\n",
    "\n",
    "# Load Saved Model\n",
    "sess = tf.Session()\n",
    "saver = tf.train.Saver()\n",
    "save_file = \"../../saved_params/GoogleNet_multitask_classification_2e-4_96\"\n",
    "saver.restore(sess, save_file) \n",
    "saved_history = pickle.load(open(save_file + \"_modelhist\", 'rb'))\n",
    "model.model_history = saved_history\n",
    "\n",
    "# Test Model Accuracy\n",
    "loss_train, acc_sbrd_train, acc_nsfw_train = model.eval(data, sess, split='train')\n",
    "loss_val, acc_sbrd_val, ac_nsfw_val = model.eval(data, sess, split = 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get model predictions\n",
    "goog_sbrd_logits, goog_nsfw_logits = sess.run(model.prediction, {model.X_placeholder: data.X_val, \\\n",
    "                                                               model.y_sbrd_placeholder: data.y_val, \\\n",
    "                                                               model.y_nsfw_placeholder: data.y_val_2, \\\n",
    "                                                               model.is_training_placeholder:False})\n",
    "goog_sbrd_pred = np.argmax(goog_sbrd_logits, axis = 1)\n",
    "goog_nsfw_pred = np.argmax(goog_nsfw_logits, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from resnet import ResNetMulticlass\n",
    "\n",
    "# Reset Graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Create model instance\n",
    "model_config = ModelConfig(eval_batch_size=3000)\n",
    "model = ResNetMulticlass(model_config)\n",
    "\n",
    "# Load Saved Model\n",
    "sess = tf.Session()\n",
    "saver = tf.train.Saver()\n",
    "save_file = \"\"\n",
    "saver.restore(sess, save_file) \n",
    "saved_history = pickle.load(open(save_file + \"_modelhist\", 'rb'))\n",
    "model.model_history = saved_history\n",
    "\n",
    "# Test Model Accuracy\n",
    "loss_train, acc_sbrd_train, acc_nsfw_train = model.eval(data, sess, split='train')\n",
    "loss_val, acc_sbrd_val, ac_nsfw_val = model.eval(data, sess, split = 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get model predictions\n",
    "res_sbrd_logits, res_nsfw_logits = sess.run(model.prediction, {model.X_placeholder: data.X_val, \\\n",
    "                                                               model.y_sbrd_placeholder: data.y_val, \\\n",
    "                                                               model.y_nsfw_placeholder: data.y_val_2, \\\n",
    "                                                               model.is_training_placeholder:False})\n",
    "res_sbrd_pred = np.argmax(res_sbrd_logits, axis = 1)\n",
    "res_nsfw_pred = np.argmax(res_nsfw_logits, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predictions is a list of prediction arrays, one for each model\n",
    "# default_prediction is a prediction array, that is defaulted to when there is no clear majority\n",
    "# returns ensembled predictions\n",
    "def majority_vote_ensemble(predictions, default_prediction):\n",
    "    from scipy import stats\n",
    "    \n",
    "    predictions = np.array(predictions)\n",
    "    num_models = predictions.shape[1]\n",
    "    mode, counts = stats.mode(preidctions)\n",
    "    indices = counts < (num_models / 2.0)  # indices of predictions with less than majority vote\n",
    "    vote_pred = mode\n",
    "    vote_pred[indices] = default_prediction[indices]\n",
    "    return vote_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Used from my CS 224N code\n",
    "def softmax(x):\n",
    "    shifted = x - np.max(x)\n",
    "    exponentiated = np.exp(shifted)\n",
    "    return exponentiated / np.sum(exponentiated)\n",
    "\n",
    "# predictions is a list of logit arrays, one for each model\n",
    "# weights is a list of weights for each model, in the same order as predictions\n",
    "# returns ensembled predictions\n",
    "def average_ensemble(logits, weights):\n",
    "    probs = np.array([softmax(x) for x in logits])\n",
    "    average_probs = np.average(probs, axis=0, weights=weights)\n",
    "    return np.argmax(average_probs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'alex_sbrd_logits' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-b97de05dd03d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mactual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msbrd_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0malex_sbrd_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgoog_sbrd_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_sbrd_logits\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mnsfw_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0malex_nsfw_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgoog_nsfw_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_nsfw_logits\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0msbrd_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0malex_sbrd_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgoog_sbrd_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_sbrd_pred\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'alex_sbrd_logits' is not defined"
     ]
    }
   ],
   "source": [
    "def accuracy(prediction, actual):\n",
    "    return np.average(prediction == actual)\n",
    "\n",
    "sbrd_logits = [alex_sbrd_logits, goog_sbrd_logits, res_sbrd_logits]\n",
    "nsfw_logits = [alex_nsfw_logits, goog_nsfw_logits, res_nsfw_logits]\n",
    "sbrd_preds = [alex_sbrd_pred, goog_sbrd_pred, res_sbrd_pred]\n",
    "nsfw_preds = [alex_nsfw_pred, goog_nsfw_pred, res_nsfw_pred]\n",
    "\n",
    "sbrd_majority_preds = majority_vote_ensemble(sbrd_preds, res_sbrd_pred)\n",
    "nsfw_majority_preds = majority_vote_ensemble(sbrd_preds, res_sbrd_pred)\n",
    "sbrd_average_preds = average_ensemble(sbrd_logits, [0.1, 0.4, 0.5])\n",
    "nsfw_average_preds = average_ensemble(sbrd_logits, [0.1, 0.4, 0.5])\n",
    "\n",
    "sbrd_majority_acc = accuracy(sbrd_majority_preds, data.y_val)\n",
    "nsfw_majority_acc = accuracy(nsfw_majority_preds, data.y_val_2)\n",
    "sbrd_average_acc = accuracy(sbrd_average_preds, data.y_val)\n",
    "nsfw_average_acc = accuracy(nsfw_average_preds, data.y_val_2)\n",
    "\n",
    "print(\"Majority vote accuracies:\")\n",
    "print(\"Subreddit: \" + str(sbrd_majority_acc))\n",
    "print(\"NSFW: \" + str(nsfw_majority_acc))\n",
    "print(\"Average accuracies:\")\n",
    "print(\"Subreddit: \" + str(sbrd_average_acc))\n",
    "print(\"NSFW: \" + str(nsfw_average_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
