{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subreddit Classification\n",
    "\n",
    "This code uses an AlexNet model to classify an image to one of 20 subreddits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import timeit\n",
    "import random\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from util import import_dataset, sample_data, plot_confusion_matrix\n",
    "from model import Model, lazy_property\n",
    "from config import ModelConfig, TrainConfig\n",
    "import hyperopt as hpropt\n",
    "%matplotlib inline\n",
    "\n",
    "# Set default to auto import packages\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (25450, 128, 128, 3)\n",
      "Train subreddit labels shape:  (25450,)\n",
      "Train nsfw labels shape:  (25450,)\n",
      "Validation data shape:  (3181, 128, 128, 3)\n",
      "Validation subreddit labels shape:  (3181,)\n",
      "Validation nsfw labels shape:  (3181,)\n",
      "Test data shape:  (3182, 128, 128, 3)\n",
      "Test subreddit labels shape:  (3182,)\n",
      "Test nsfw labels shape:  (3182,)\n"
     ]
    }
   ],
   "source": [
    "# Form training, developement, and testing data sets\n",
    "address = r'/home/tylerchase/CS-231N-Final-Project/data/fullData//'\n",
    "file_names = {}\n",
    "file_names['images'] = 'full_data.npy'\n",
    "file_names['subs'] = 'full_subredditlabels'\n",
    "file_names['dict'] = 'full_subredditIndex'\n",
    "file_names['nsfw'] = 'full_nsfwlabels'\n",
    "data, dictionary = import_dataset(address, file_names)\n",
    "\n",
    "# Print the sizes as a sanity check\n",
    "print('Train data shape: ', data.X_train.shape)\n",
    "print('Train subreddit labels shape: ', data.y_train.shape)\n",
    "print('Train nsfw labels shape: ', data.y_train_2.shape)\n",
    "print('Validation data shape: ', data.X_val.shape)\n",
    "print('Validation subreddit labels shape: ', data.y_val.shape)\n",
    "print('Validation nsfw labels shape: ', data.y_val_2.shape)\n",
    "print('Test data shape: ', data.X_test.shape)\n",
    "print('Test subreddit labels shape: ', data.y_test.shape)\n",
    "print('Test nsfw labels shape: ', data.y_test_2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional Cell to take Particular Subreddits from Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subreddits = ['gonewild', 'ladybonersgw', 'PrettyGirls', 'LadyBoners']\n",
    "dictionary = sample_data(subreddits, data, dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define AlexNet model \n",
    "\n",
    "* 11x11 convolutional layer with 96 filters and a stride of 4\n",
    "* ReLU activation\n",
    "* 3x3 max pooling with a stride of 2\n",
    "* batch normalization\n",
    "\n",
    "\n",
    "* 5x5 convolutional layer with 256 filters and a stride of 1\n",
    "* ReLU activation\n",
    "* 3x3 max pooling with a stride of 2\n",
    "* batch normalization\n",
    "\n",
    "\n",
    "* 3x3 convolutional layer with 384 filters and a stride of 1\n",
    "* ReLU activation\n",
    "* 3x3 convolutional layer with 384 filters and a stride of 1\n",
    "* ReLU activation \n",
    "* 3x3 convolutional layer with 256 filters and a stride of 1\n",
    "* ReLU activation\n",
    "* 3x3 max pooling with a stride of 2\n",
    "\n",
    "\n",
    "* affine layer from 4096 to 4096\n",
    "* ReLU activation\n",
    "* affine layer from 4096 to 4096\n",
    "* ReLU activation\n",
    "* affine layer from 4096 to 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AlexNet(Model):\n",
    "    \n",
    "    def __init__(self, model_config):\n",
    "        Model.__init__(self, model_config)\n",
    "  \n",
    "    @lazy_property\n",
    "    def prediction(self):\n",
    "        # define our graph (e.g. AlexNet)\n",
    "        \n",
    "        a1 = tf.layers.conv2d(self.X_placeholder, filters=96, kernel_size=(11,11), strides=(4,4), padding='SAME') \n",
    "        h1 = tf.nn.relu(a1)\n",
    "        mp1 = tf.layers.max_pooling2d(h1, pool_size=(3,3), strides=(2,2), padding='SAME')    \n",
    "        bn1 = tf.layers.batch_normalization(mp1, training=self.is_training_placeholder)\n",
    "        \n",
    "        a2 = tf.layers.conv2d(bn1, filters=256, kernel_size=(5,5), strides=(1,1), padding='SAME')     \n",
    "        h2 = tf.nn.relu(a2)\n",
    "        mp2 = tf.layers.max_pooling2d(h2, pool_size=(3,3), strides=(2,2), padding='SAME')    \n",
    "        bn2 = tf.layers.batch_normalization(mp2, training=self.is_training_placeholder)              \n",
    "    \n",
    "        a3 = tf.layers.conv2d(bn2, filters=384, kernel_size=(3,3), strides=(1,1), padding='SAME')    \n",
    "        h3 = tf.nn.relu(a3)\n",
    "        a4 = tf.layers.conv2d(h3, filters=384, kernel_size=(3,3), strides=(1,1), padding='SAME')   \n",
    "        h4 = tf.nn.relu(a4)\n",
    "        a5 = tf.layers.conv2d(h4, filters=256, kernel_size=(3,3), strides=(1,1), padding='SAME')    \n",
    "        h5 = tf.nn.relu(a5)\n",
    "        mp3 = tf.layers.max_pooling2d(h5, pool_size=(3,3), strides=(2,2), padding='SAME')  \n",
    "    \n",
    "        mp_flat = tf.reshape(mp3,[-1,4096])\n",
    "        aff1 = tf.layers.dense(mp_flat, 2048)\n",
    "        h6 = tf.nn.relu(aff1)\n",
    "        aff2 = tf.layers.dense(h6, 2048)\n",
    "        h7 = tf.nn.relu(aff2)\n",
    "        y_out = tf.layers.dense(h7, self.config.subreddit_class_size)\n",
    "    \n",
    "        return y_out        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional Cell to Train the Model with Specific Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create model instance\n",
    "tf.reset_default_graph()\n",
    "\n",
    "model_config = ModelConfig(learning_rate=0.003)\n",
    "train_config = TrainConfig(num_epochs=20, train_batch_size=100, print_every=100, lr_decay=0.98,\\\n",
    "    saver_address=r'../../subreddit_classification_parameters/', \\\n",
    "    save_file_name = 'AlexNet_subreddit_classification_2')\n",
    "model = AlexNet(model_config)\n",
    "\n",
    "# Create session\n",
    "session = tf.Session()\n",
    "model.train(data, session, train_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Return Loss and Accuracy History for Model Above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot Loss and Accuracy\n",
    "model.plot_loss_acc(data, save_address = '../../AlexNet_plots//', save_name = 'subreddit_history', \\\n",
    "    title_font = 20, tick_font = 20, legend_font = 15, axis_font = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional Cell for Hyperparameter Search over a Range of Hyperparameter Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_config = ModelConfig(learning_rate=0.003)\n",
    "\n",
    "train_config = TrainConfig(num_epochs=8, \n",
    "                    train_batch_size=100, \n",
    "                    print_every=1000)\n",
    "modelHP = AlexNet(model_config)\n",
    "session = tf.Session()\n",
    "\n",
    "def objective(args):\n",
    "\n",
    "    tf.reset_default_graph()\n",
    "    modelHP = AlexNet(model_config)\n",
    "    session = tf.Session()\n",
    "    \n",
    "    #train_config.num_epochs = args['Nepochs']\n",
    "    train_config.lr_decay = args['decayRate']\n",
    "    modelHP.config.learning_rate = args['learningRate']\n",
    "    #modelHP.config.sbrd_weight = args['costWeight']\n",
    "    \n",
    "    modelHP.train(data, session, train_config)\n",
    "    cost, accuracy = modelHP.eval(data, session, \"val\")\n",
    "    \n",
    "    saveList = {\n",
    "        'accuracy_sbrd' : accuracy,\n",
    "        'cost' : cost,\n",
    "        #'Nepochs' : args['Nepochs'],\n",
    "        'learningRate' : args['learningRate'],\n",
    "        'decayRate' : args['decayRate']\n",
    "        #'costWeight' : args['costWeight']\n",
    "    }    \n",
    "    pickle.dump(saveList, open(\"../../hprOpt_AlexNetSubreddit/hprPrmOpt_\" + str(accuracy) + \"_\" + str(cost) + \".dat\", \"wb\"))\n",
    "    \n",
    "    return cost\n",
    "\n",
    "def optimize():\n",
    "    \n",
    "    space = {\n",
    "        #'Nepochs' : hpropt.hp.randint('Nepochs', 70),\n",
    "        'learningRate' : hpropt.hp.loguniform('learningRate', -8.1, -3.5),\n",
    "        'decayRate' : hpropt.hp.uniform('decayRate', 0.95, 1)\n",
    "        #'costWeight' : hpropt.hp.uniform('costWeight', 0.5, 1)\n",
    "    }\n",
    "    \n",
    "    best = hpropt.fmin(objective, space, algo=hpropt.tpe.suggest, max_evals=100)\n",
    "    print(best)\n",
    "    \n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n",
      "Epoch 1 training finished in 53.051954 seconds\n",
      "train accuracy:24.9%\n",
      "val accuracy:24.8%\n",
      "Epoch 1 evaluation finished in 29.974239 seconds\n",
      "---------------------------------------------------------\n",
      "Epoch 2 training finished in 47.205213 seconds\n",
      "train accuracy:27.7%\n",
      "val accuracy:26.8%\n",
      "Epoch 2 evaluation finished in 15.521127 seconds\n",
      "---------------------------------------------------------\n",
      "Epoch 3 training finished in 47.242534 seconds\n",
      "train accuracy:34.4%\n",
      "val accuracy:33.4%\n",
      "Epoch 3 evaluation finished in 15.605551 seconds\n",
      "---------------------------------------------------------\n",
      "Epoch 4 training finished in 47.150898 seconds\n",
      "train accuracy:35.2%\n",
      "val accuracy:33.7%\n",
      "Epoch 4 evaluation finished in 15.489132 seconds\n",
      "---------------------------------------------------------\n",
      "Epoch 5 training finished in 47.315280 seconds\n",
      "train accuracy:38.1%\n",
      "val accuracy:35.5%\n",
      "Epoch 5 evaluation finished in 15.750516 seconds\n",
      "---------------------------------------------------------\n",
      "Epoch 6 training finished in 47.169367 seconds\n",
      "train accuracy:41.0%\n",
      "val accuracy:38.6%\n",
      "Epoch 6 evaluation finished in 15.607558 seconds\n",
      "---------------------------------------------------------\n",
      "Epoch 7 training finished in 47.282475 seconds\n",
      "train accuracy:42.2%\n",
      "val accuracy:39.0%\n",
      "Epoch 7 evaluation finished in 15.566326 seconds\n",
      "---------------------------------------------------------\n",
      "Epoch 8 training finished in 47.383707 seconds\n",
      "train accuracy:42.6%\n",
      "val accuracy:39.3%\n",
      "Epoch 8 evaluation finished in 15.768253 seconds\n",
      "val accuracy:39.3%\n",
      "---------------------------------------------------------\n",
      "Epoch 1 training finished in 47.743009 seconds\n",
      "train accuracy:35.6%\n",
      "val accuracy:35.1%\n",
      "Epoch 1 evaluation finished in 15.499247 seconds\n",
      "---------------------------------------------------------\n",
      "Epoch 2 training finished in 47.645665 seconds\n",
      "train accuracy:43.1%\n",
      "val accuracy:40.0%\n",
      "Epoch 2 evaluation finished in 15.627015 seconds\n",
      "---------------------------------------------------------\n",
      "Epoch 3 training finished in 47.778744 seconds\n",
      "train accuracy:52.1%\n",
      "val accuracy:46.2%\n",
      "Epoch 3 evaluation finished in 15.653497 seconds\n",
      "---------------------------------------------------------\n",
      "Epoch 4 training finished in 47.692451 seconds\n",
      "train accuracy:54.0%\n",
      "val accuracy:46.7%\n",
      "Epoch 4 evaluation finished in 15.658682 seconds\n",
      "---------------------------------------------------------\n",
      "Epoch 5 training finished in 47.654439 seconds\n",
      "train accuracy:57.6%\n",
      "val accuracy:46.9%\n",
      "Epoch 5 evaluation finished in 15.763825 seconds\n",
      "---------------------------------------------------------\n",
      "Epoch 6 training finished in 47.694988 seconds\n",
      "train accuracy:53.4%\n",
      "val accuracy:42.5%\n",
      "Epoch 6 evaluation finished in 15.589263 seconds\n",
      "---------------------------------------------------------\n",
      "Epoch 7 training finished in 47.640801 seconds\n",
      "train accuracy:56.5%\n",
      "val accuracy:43.6%\n",
      "Epoch 7 evaluation finished in 15.784082 seconds\n",
      "---------------------------------------------------------\n",
      "Epoch 8 training finished in 47.731657 seconds\n",
      "train accuracy:59.7%\n",
      "val accuracy:43.0%\n",
      "Epoch 8 evaluation finished in 15.674167 seconds\n",
      "val accuracy:43.0%\n",
      "---------------------------------------------------------\n",
      "Epoch 1 training finished in 46.670548 seconds\n",
      "train accuracy:15.7%\n",
      "val accuracy:13.9%\n",
      "Epoch 1 evaluation finished in 15.668232 seconds\n",
      "---------------------------------------------------------\n",
      "Epoch 2 training finished in 46.900752 seconds\n",
      "train accuracy:25.0%\n",
      "val accuracy:25.2%\n",
      "Epoch 2 evaluation finished in 15.616454 seconds\n",
      "---------------------------------------------------------\n",
      "Epoch 3 training finished in 47.021244 seconds\n",
      "train accuracy:32.1%\n",
      "val accuracy:31.9%\n",
      "Epoch 3 evaluation finished in 15.648222 seconds\n",
      "---------------------------------------------------------\n",
      "Epoch 4 training finished in 47.339588 seconds\n",
      "train accuracy:36.2%\n",
      "val accuracy:35.1%\n",
      "Epoch 4 evaluation finished in 15.747359 seconds\n",
      "---------------------------------------------------------\n",
      "Epoch 5 training finished in 47.480417 seconds\n",
      "train accuracy:36.1%\n",
      "val accuracy:33.1%\n",
      "Epoch 5 evaluation finished in 15.750320 seconds\n",
      "---------------------------------------------------------\n",
      "Epoch 6 training finished in 47.641814 seconds\n",
      "train accuracy:41.2%\n",
      "val accuracy:38.7%\n",
      "Epoch 6 evaluation finished in 15.866988 seconds\n",
      "---------------------------------------------------------\n",
      "Epoch 7 training finished in 47.572472 seconds\n",
      "train accuracy:43.3%\n",
      "val accuracy:40.7%\n",
      "Epoch 7 evaluation finished in 15.660025 seconds\n",
      "---------------------------------------------------------\n",
      "Epoch 8 training finished in 47.534536 seconds\n",
      "train accuracy:44.8%\n",
      "val accuracy:42.3%\n",
      "Epoch 8 evaluation finished in 15.718752 seconds\n",
      "val accuracy:42.3%\n",
      "---------------------------------------------------------\n",
      "Epoch 1 training finished in 46.862796 seconds\n",
      "train accuracy:6.5%\n",
      "val accuracy:6.6%\n",
      "Epoch 1 evaluation finished in 15.713737 seconds\n",
      "---------------------------------------------------------\n",
      "Epoch 2 training finished in 46.901489 seconds\n",
      "train accuracy:6.1%\n",
      "val accuracy:6.1%\n",
      "Epoch 2 evaluation finished in 15.870404 seconds\n",
      "---------------------------------------------------------\n",
      "Epoch 3 training finished in 46.865904 seconds\n",
      "train accuracy:6.3%\n",
      "val accuracy:6.5%\n",
      "Epoch 3 evaluation finished in 15.782510 seconds\n",
      "---------------------------------------------------------\n",
      "Epoch 4 training finished in 46.809616 seconds\n",
      "train accuracy:6.4%\n",
      "val accuracy:6.6%\n",
      "Epoch 4 evaluation finished in 15.803885 seconds\n",
      "---------------------------------------------------------\n",
      "Epoch 5 training finished in 46.621938 seconds\n",
      "train accuracy:5.2%\n",
      "val accuracy:5.4%\n",
      "Epoch 5 evaluation finished in 15.475221 seconds\n",
      "---------------------------------------------------------\n",
      "Epoch 6 training finished in 46.222062 seconds\n",
      "train accuracy:5.2%\n",
      "val accuracy:5.1%\n",
      "Epoch 6 evaluation finished in 15.797472 seconds\n",
      "---------------------------------------------------------\n",
      "Epoch 7 training finished in 46.192630 seconds\n",
      "train accuracy:5.2%\n",
      "val accuracy:5.1%\n",
      "Epoch 7 evaluation finished in 15.763739 seconds\n",
      "---------------------------------------------------------\n",
      "Epoch 8 training finished in 46.162729 seconds\n",
      "train accuracy:5.2%\n",
      "val accuracy:5.1%\n",
      "Epoch 8 evaluation finished in 15.711011 seconds\n",
      "val accuracy:5.1%\n",
      "---------------------------------------------------------\n",
      "Epoch 1 training finished in 46.214048 seconds\n",
      "train accuracy:5.2%\n",
      "val accuracy:5.1%\n",
      "Epoch 1 evaluation finished in 15.643577 seconds\n",
      "---------------------------------------------------------\n",
      "Epoch 2 training finished in 46.044730 seconds\n",
      "train accuracy:5.2%\n",
      "val accuracy:5.1%\n",
      "Epoch 2 evaluation finished in 15.680017 seconds\n",
      "---------------------------------------------------------\n",
      "Epoch 3 training finished in 46.191421 seconds\n",
      "train accuracy:5.2%\n",
      "val accuracy:5.1%\n",
      "Epoch 3 evaluation finished in 15.639639 seconds\n",
      "---------------------------------------------------------\n",
      "Epoch 4 training finished in 46.142055 seconds\n",
      "train accuracy:5.2%\n",
      "val accuracy:5.1%\n",
      "Epoch 4 evaluation finished in 15.680482 seconds\n",
      "---------------------------------------------------------\n",
      "Epoch 5 training finished in 46.154845 seconds\n",
      "train accuracy:5.2%\n",
      "val accuracy:5.1%\n",
      "Epoch 5 evaluation finished in 15.700497 seconds\n",
      "---------------------------------------------------------\n",
      "Epoch 6 training finished in 45.979932 seconds\n",
      "train accuracy:5.2%\n",
      "val accuracy:5.1%\n",
      "Epoch 6 evaluation finished in 15.868655 seconds\n",
      "---------------------------------------------------------\n",
      "Epoch 7 training finished in 46.073447 seconds\n",
      "train accuracy:5.2%\n",
      "val accuracy:5.1%\n",
      "Epoch 7 evaluation finished in 15.521155 seconds\n",
      "---------------------------------------------------------\n",
      "Epoch 8 training finished in 46.122484 seconds\n",
      "train accuracy:5.2%\n",
      "val accuracy:5.1%\n",
      "Epoch 8 evaluation finished in 15.874514 seconds\n",
      "val accuracy:5.1%\n",
      "---------------------------------------------------------\n",
      "Epoch 1 training finished in 47.725223 seconds\n",
      "train accuracy:27.4%\n",
      "val accuracy:27.9%\n",
      "Epoch 1 evaluation finished in 15.683452 seconds\n",
      "---------------------------------------------------------\n",
      "Epoch 2 training finished in 47.697824 seconds\n",
      "train accuracy:38.1%\n",
      "val accuracy:37.0%\n",
      "Epoch 2 evaluation finished in 15.881308 seconds\n",
      "---------------------------------------------------------\n",
      "Epoch 3 training finished in 47.677305 seconds\n",
      "train accuracy:44.4%\n",
      "val accuracy:41.3%\n",
      "Epoch 3 evaluation finished in 15.635109 seconds\n",
      "---------------------------------------------------------\n",
      "Epoch 4 training finished in 47.575293 seconds\n",
      "train accuracy:47.3%\n",
      "val accuracy:42.9%\n",
      "Epoch 4 evaluation finished in 15.678138 seconds\n",
      "---------------------------------------------------------\n",
      "Epoch 5 training finished in 47.665155 seconds\n",
      "train accuracy:50.6%\n",
      "val accuracy:47.0%\n",
      "Epoch 5 evaluation finished in 15.643639 seconds\n",
      "---------------------------------------------------------\n",
      "Epoch 6 training finished in 47.589667 seconds\n",
      "train accuracy:52.7%\n",
      "val accuracy:47.4%\n",
      "Epoch 6 evaluation finished in 15.662751 seconds\n",
      "---------------------------------------------------------\n",
      "Epoch 7 training finished in 47.692130 seconds\n",
      "train accuracy:53.7%\n",
      "val accuracy:45.7%\n",
      "Epoch 7 evaluation finished in 15.715984 seconds\n",
      "---------------------------------------------------------\n",
      "Epoch 8 training finished in 47.718719 seconds\n",
      "train accuracy:53.6%\n",
      "val accuracy:45.6%\n",
      "Epoch 8 evaluation finished in 15.660836 seconds\n",
      "val accuracy:45.6%\n",
      "---------------------------------------------------------\n",
      "Epoch 1 training finished in 47.815186 seconds\n",
      "train accuracy:20.0%\n",
      "val accuracy:19.4%\n",
      "Epoch 1 evaluation finished in 15.875134 seconds\n",
      "---------------------------------------------------------\n",
      "Epoch 2 training finished in 47.469785 seconds\n",
      "train accuracy:21.8%\n",
      "val accuracy:22.4%\n",
      "Epoch 2 evaluation finished in 15.650090 seconds\n",
      "---------------------------------------------------------\n",
      "Epoch 3 training finished in 47.691187 seconds\n",
      "train accuracy:28.3%\n",
      "val accuracy:28.3%\n",
      "Epoch 3 evaluation finished in 15.807641 seconds\n",
      "---------------------------------------------------------\n",
      "Epoch 4 training finished in 47.700220 seconds\n",
      "train accuracy:34.2%\n",
      "val accuracy:33.8%\n",
      "Epoch 4 evaluation finished in 15.818504 seconds\n",
      "---------------------------------------------------------\n",
      "Epoch 5 training finished in 47.716245 seconds\n",
      "train accuracy:37.4%\n",
      "val accuracy:34.8%\n",
      "Epoch 5 evaluation finished in 15.830502 seconds\n",
      "---------------------------------------------------------\n",
      "Epoch 6 training finished in 47.655123 seconds\n",
      "train accuracy:36.5%\n",
      "val accuracy:34.0%\n",
      "Epoch 6 evaluation finished in 15.746002 seconds\n",
      "---------------------------------------------------------\n",
      "Epoch 7 training finished in 47.689861 seconds\n",
      "train accuracy:41.5%\n",
      "val accuracy:38.4%\n",
      "Epoch 7 evaluation finished in 15.714925 seconds\n",
      "---------------------------------------------------------\n",
      "Epoch 8 training finished in 47.769725 seconds\n",
      "train accuracy:41.9%\n",
      "val accuracy:38.8%\n",
      "Epoch 8 evaluation finished in 15.890271 seconds\n",
      "val accuracy:38.8%\n",
      "---------------------------------------------------------\n",
      "Epoch 1 training finished in 46.305786 seconds\n",
      "train accuracy:5.2%\n",
      "val accuracy:5.1%\n",
      "Epoch 1 evaluation finished in 15.748373 seconds\n",
      "---------------------------------------------------------\n",
      "Epoch 2 training finished in 46.186850 seconds\n",
      "train accuracy:5.2%\n",
      "val accuracy:5.1%\n",
      "Epoch 2 evaluation finished in 15.430810 seconds\n",
      "---------------------------------------------------------\n",
      "Epoch 3 training finished in 46.153644 seconds\n",
      "train accuracy:5.2%\n",
      "val accuracy:5.1%\n",
      "Epoch 3 evaluation finished in 15.705093 seconds\n",
      "---------------------------------------------------------\n",
      "Epoch 4 training finished in 46.176220 seconds\n",
      "train accuracy:5.2%\n",
      "val accuracy:5.1%\n",
      "Epoch 4 evaluation finished in 15.738178 seconds\n",
      "---------------------------------------------------------\n",
      "Epoch 5 training finished in 46.170230 seconds\n",
      "train accuracy:5.2%\n",
      "val accuracy:5.1%\n",
      "Epoch 5 evaluation finished in 15.716993 seconds\n",
      "---------------------------------------------------------\n",
      "Epoch 6 training finished in 46.224234 seconds\n",
      "train accuracy:5.2%\n",
      "val accuracy:5.1%\n",
      "Epoch 6 evaluation finished in 15.911135 seconds\n",
      "---------------------------------------------------------\n",
      "Epoch 7 training finished in 46.126090 seconds\n",
      "train accuracy:5.2%\n",
      "val accuracy:5.1%\n",
      "Epoch 7 evaluation finished in 15.872099 seconds\n",
      "---------------------------------------------------------\n",
      "Epoch 8 training finished in 46.212630 seconds\n",
      "train accuracy:5.2%\n",
      "val accuracy:5.1%\n",
      "Epoch 8 evaluation finished in 15.773741 seconds\n",
      "val accuracy:5.1%\n",
      "---------------------------------------------------------\n",
      "Epoch 1 training finished in 46.361565 seconds\n",
      "train accuracy:5.2%\n",
      "val accuracy:5.1%\n",
      "Epoch 1 evaluation finished in 15.722084 seconds\n",
      "---------------------------------------------------------\n",
      "Epoch 2 training finished in 46.278948 seconds\n",
      "train accuracy:5.2%\n",
      "val accuracy:5.1%\n",
      "Epoch 2 evaluation finished in 15.668805 seconds\n",
      "---------------------------------------------------------\n",
      "Epoch 3 training finished in 46.236732 seconds\n",
      "train accuracy:5.2%\n",
      "val accuracy:5.1%\n",
      "Epoch 3 evaluation finished in 15.663563 seconds\n",
      "---------------------------------------------------------\n",
      "Epoch 4 training finished in 46.322177 seconds\n",
      "train accuracy:5.2%\n",
      "val accuracy:5.1%\n",
      "Epoch 4 evaluation finished in 15.857500 seconds\n",
      "---------------------------------------------------------\n",
      "Epoch 5 training finished in 46.290407 seconds\n",
      "train accuracy:5.2%\n",
      "val accuracy:5.1%\n",
      "Epoch 5 evaluation finished in 15.868504 seconds\n",
      "---------------------------------------------------------\n",
      "Epoch 6 training finished in 46.237405 seconds\n",
      "train accuracy:5.2%\n",
      "val accuracy:5.1%\n",
      "Epoch 6 evaluation finished in 15.761752 seconds\n",
      "---------------------------------------------------------\n",
      "Epoch 7 training finished in 46.252148 seconds\n",
      "train accuracy:5.2%\n",
      "val accuracy:5.1%\n",
      "Epoch 7 evaluation finished in 15.771424 seconds\n",
      "---------------------------------------------------------\n",
      "Epoch 8 training finished in 46.287853 seconds\n",
      "train accuracy:5.2%\n",
      "val accuracy:5.1%\n",
      "Epoch 8 evaluation finished in 15.769145 seconds\n",
      "val accuracy:5.1%\n",
      "---------------------------------------------------------\n",
      "Epoch 1 training finished in 47.684020 seconds\n",
      "train accuracy:20.9%\n",
      "val accuracy:21.3%\n",
      "Epoch 1 evaluation finished in 15.788803 seconds\n",
      "---------------------------------------------------------\n",
      "Epoch 2 training finished in 47.660003 seconds\n",
      "train accuracy:30.2%\n",
      "val accuracy:29.4%\n",
      "Epoch 2 evaluation finished in 15.754359 seconds\n",
      "---------------------------------------------------------\n",
      "Epoch 3 training finished in 47.680895 seconds\n",
      "train accuracy:38.0%\n",
      "val accuracy:37.5%\n",
      "Epoch 3 evaluation finished in 15.784346 seconds\n",
      "---------------------------------------------------------\n",
      "Epoch 4 training finished in 47.746750 seconds\n",
      "train accuracy:42.9%\n",
      "val accuracy:39.4%\n",
      "Epoch 4 evaluation finished in 15.680341 seconds\n",
      "---------------------------------------------------------\n",
      "Epoch 5 training finished in 47.718376 seconds\n",
      "train accuracy:47.3%\n",
      "val accuracy:43.2%\n",
      "Epoch 5 evaluation finished in 15.782215 seconds\n",
      "---------------------------------------------------------\n",
      "Epoch 6 training finished in 47.709821 seconds\n",
      "train accuracy:44.1%\n",
      "val accuracy:40.8%\n",
      "Epoch 6 evaluation finished in 15.769470 seconds\n",
      "---------------------------------------------------------\n",
      "Epoch 7 training finished in 47.687129 seconds\n",
      "train accuracy:49.7%\n",
      "val accuracy:43.2%\n",
      "Epoch 7 evaluation finished in 15.527026 seconds\n",
      "---------------------------------------------------------\n",
      "Epoch 8 training finished in 47.570135 seconds\n",
      "train accuracy:50.9%\n",
      "val accuracy:43.4%\n",
      "Epoch 8 evaluation finished in 15.778119 seconds\n",
      "val accuracy:43.4%\n",
      "---------------------------------------------------------\n",
      "Epoch 1 training finished in 46.533414 seconds\n",
      "train accuracy:5.2%\n",
      "val accuracy:5.0%\n",
      "Epoch 1 evaluation finished in 15.805979 seconds\n",
      "---------------------------------------------------------\n",
      "Epoch 2 training finished in 46.243176 seconds\n",
      "train accuracy:5.2%\n",
      "val accuracy:5.1%\n",
      "Epoch 2 evaluation finished in 15.566585 seconds\n",
      "---------------------------------------------------------\n",
      "Epoch 3 training finished in 46.227414 seconds\n",
      "train accuracy:5.2%\n",
      "val accuracy:5.1%\n",
      "Epoch 3 evaluation finished in 15.585244 seconds\n",
      "---------------------------------------------------------\n",
      "Epoch 4 training finished in 46.097866 seconds\n",
      "train accuracy:5.2%\n",
      "val accuracy:5.1%\n",
      "Epoch 4 evaluation finished in 15.681933 seconds\n",
      "---------------------------------------------------------\n",
      "Epoch 5 training finished in 46.097652 seconds\n",
      "train accuracy:5.2%\n",
      "val accuracy:5.1%\n",
      "Epoch 5 evaluation finished in 15.816623 seconds\n",
      "---------------------------------------------------------\n",
      "Epoch 6 training finished in 46.165613 seconds\n",
      "train accuracy:5.2%\n",
      "val accuracy:5.1%\n",
      "Epoch 6 evaluation finished in 15.708910 seconds\n",
      "---------------------------------------------------------\n",
      "Epoch 7 training finished in 46.233609 seconds\n",
      "train accuracy:5.2%\n",
      "val accuracy:5.1%\n",
      "Epoch 7 evaluation finished in 15.831417 seconds\n",
      "---------------------------------------------------------\n",
      "Epoch 8 training finished in 46.054854 seconds\n",
      "train accuracy:5.2%\n",
      "val accuracy:5.1%\n",
      "Epoch 8 evaluation finished in 15.751627 seconds\n",
      "val accuracy:5.1%\n",
      "---------------------------------------------------------\n",
      "Epoch 1 training finished in 47.357388 seconds\n",
      "train accuracy:8.7%\n",
      "val accuracy:9.2%\n",
      "Epoch 1 evaluation finished in 15.818596 seconds\n",
      "---------------------------------------------------------\n",
      "Epoch 2 training finished in 47.209931 seconds\n",
      "train accuracy:8.8%\n",
      "val accuracy:9.2%\n",
      "Epoch 2 evaluation finished in 15.892952 seconds\n",
      "---------------------------------------------------------\n",
      "Epoch 3 training finished in 47.317074 seconds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-4f576df864ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-4-f5e4254f79ee>\u001b[0m in \u001b[0;36moptimize\u001b[1;34m()\u001b[0m\n\u001b[0;32m     42\u001b[0m     }\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m     \u001b[0mbest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhpropt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malgo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhpropt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtpe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_evals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/cs231n/myVE35/lib/python3.5/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin)\u001b[0m\n\u001b[0;32m    318\u001b[0m                     verbose=verbose)\n\u001b[0;32m    319\u001b[0m     \u001b[0mrval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 320\u001b[1;33m     \u001b[0mrval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    321\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/cs231n/myVE35/lib/python3.5/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    197\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/cs231n/myVE35/lib/python3.5/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, N, block_until_done)\u001b[0m\n\u001b[0;32m    171\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m                 \u001b[1;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstopped\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/cs231n/myVE35/lib/python3.5/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[1;34m(self, N)\u001b[0m\n\u001b[0;32m     90\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m                     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'job exception: %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/cs231n/myVE35/lib/python3.5/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[0;32m    838\u001b[0m                 \u001b[0mmemo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmemo\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    839\u001b[0m                 print_node_on_error=self.rec_eval_print_node_on_error)\n\u001b[1;32m--> 840\u001b[1;33m             \u001b[0mrval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    841\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    842\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-f5e4254f79ee>\u001b[0m in \u001b[0;36mobjective\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;31m#modelHP.config.sbrd_weight = args['costWeight']\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mmodelHP\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[0mcost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodelHP\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"val\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/tylerchase/CS-231N-Final-Project/src/models/model.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, data, session, train_config, resume)\u001b[0m\n\u001b[0;32m    130\u001b[0m             \u001b[0mvariables\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m             \u001b[0mstartTime_eval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m             \u001b[0mloss_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"train\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m             \u001b[0mloss_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"val\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m             \u001b[0mevaluation_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstartTime_eval\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/tylerchase/CS-231N-Final-Project/src/models/model.py\u001b[0m in \u001b[0;36meval\u001b[1;34m(self, data, session, split)\u001b[0m\n\u001b[0;32m    181\u001b[0m             \u001b[0mvariables\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m             cost_i, accuracy_i = session.run(variables, \\\n\u001b[1;32m--> 183\u001b[1;33m                 {self.X_placeholder:batch_X, self.y_placeholder:batch_y, self.is_training_placeholder:False})\n\u001b[0m\u001b[0;32m    184\u001b[0m             \u001b[0mnum_sampled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m             \u001b[0mcost\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mcost_i\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/cs231n/myVE35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    765\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 767\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    768\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/cs231n/myVE35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    963\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 965\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    966\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/cs231n/myVE35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1013\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1015\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1016\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m/home/cs231n/myVE35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1020\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1021\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1022\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1023\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/cs231n/myVE35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1004\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1005\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Loading the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reset Graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Create model instance\n",
    "model_config = ModelConfig(learning_rate=0.003)\n",
    "train_config = TrainConfig(num_epochs=2, minibatch_size=100, print_every=100, \\\n",
    "    saver_address=r'../../subreddit_classification_parameters/', \\\n",
    "    save_file_name = 'AlexNet_subreddit_classification')\n",
    "model = AlexNet(model_config)\n",
    "\n",
    "# Load Saved Model\n",
    "session = tf.Session()\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(session, train_config.saver_address + train_config.save_file_name) \n",
    "\n",
    "# Test Model Accuracy\n",
    "loss_train, acc_train = model.eval(data, session, split='train')\n",
    "loss_val, acc_val = model.eval(data, session, split = 'val')\n",
    "\n",
    "print('Training Accuracy {:3.1f}%, Vallidation Accuracy:{:3.1f}%'.format((100*acc_train), (100*acc_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Predictions for Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_val_pred = session.run(model.prediction, {model.X_placeholder: data.X_val, model.y_placeholder: data.y_val, \n",
    "                                            model.is_training_placeholder:False})\n",
    "\n",
    "y_val_pred = np.argmax(y_val_pred, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Plot Confusion Matrix for Subreddit Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classes = [\"\"] * len(dictionary)\n",
    "for sub, ind in dictionary.items():\n",
    "    classes[ind] = sub\n",
    "\n",
    "conf = confusion_matrix(data.y_val, y_val_pred)\n",
    "plot_confusion_matrix(conf, classes=classes, normalize = True, tick_font = 12, box_font = 10, \\\n",
    "    axis_font = 40, title_font = 50, colorbar_font = 20,\\\n",
    "    left_space = 0.2, right_space = 1, top_space = 0.97, bottom_space = 0.05, \\\n",
    "    save_address = '../../AlexNet_plots//', save_name = 'subreddit_confusion')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Output Predictions for Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_cost, test_acc = model.eval(data, session, \"test\")\n",
    "\n",
    "\n",
    "y_test_pred = session.run(model.prediction, {model.X_placeholder: data.X_test, model.y_placeholder: data.y_test, \n",
    "                                            model.is_training_placeholder:False})\n",
    "\n",
    "y_test_pred = np.argmax(y_test_pred, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Confusion Matrix for Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classes = [\"\"] * len(dictionary)\n",
    "for sub, ind in dictionary.items():\n",
    "    classes[ind] = sub\n",
    "\n",
    "conf = confusion_matrix(data.y_test, y_test_pred)\n",
    "plot_confusion_matrix(conf, classes=classes, normalize = True, tick_font = 12, box_font = 10, \\\n",
    "    axis_font = 40, title_font = 50, colorbar_font = 20,\\\n",
    "    left_space = 0.2, right_space = 1, top_space = 0.97, bottom_space = 0.05, \\\n",
    "    save_address = '../../AlexNet_plots//', save_name = 'subreddit_confusion_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
