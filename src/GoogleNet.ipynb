{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import util\n",
    "\n",
    "address = '../data/'\n",
    "file_names = {}\n",
    "file_names['images'] = 'small_data.npy'\n",
    "file_names['subs'] = 'small_subredditlabels'\n",
    "file_names['dict'] = 'small_subredditIndex'\n",
    "X_train, y_train, X_val, y_val, X_test, y_test, dictionary = util.import_dataset(address, file_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Refer to original paper (https://arxiv.org/pdf/1502.03167.pdf) for details\n",
    "# strided boolean refers to whether the incception module employs stride-2 conv/pool layers, along with a pass through \n",
    "# projection layer, as referenced in the paper above (inception modules 3c and 4e)\n",
    "def Inception(input_layer, num_1x1, num_3x3_reduce, num_3x3, num_double_3x3_reduce, num_double_3x3, pool_type, proj_size, strided):\n",
    "    strides = [2, 2] if strided else [1, 1]  # last layer strides (before concatenation)\n",
    "    \n",
    "    inception_1_conv1 = tf.layers.conv2d(input_layer, num_1x1, [1, 1], strides=strides, padding=\"SAME\")\n",
    "    if num_1x1 > 0:\n",
    "        inception_1_bn1 = tf.layers.batch_normalization(inception_1_conv1, training=is_training)\n",
    "        inception_1 = tf.nn.relu(inception_1_bn1)\n",
    "    else:\n",
    "        inception_1 = inception_1_conv1  # tensor with no elements\n",
    "    \n",
    "    inception_2_conv1 = tf.layers.conv2d(input_layer, num_3x3_reduce, [1, 1], strides=[1, 1], padding=\"SAME\", activation=tf.nn.relu)\n",
    "    inception_2_conv2 = tf.layers.conv2d(inception_2_conv1, num_3x3, [3, 3], strides=strides, padding=\"SAME\")\n",
    "    inception_2_bn1 = tf.layers.batch_normalization(inception_2_conv2, training=is_training)\n",
    "    inception_2 = tf.nn.relu(inception_2_bn1)\n",
    "    \n",
    "    inception_3_conv1 = tf.layers.conv2d(input_layer, 64, [1, 1], strides=[1, 1], padding=\"SAME\", activation=tf.nn.relu)\n",
    "    inception_3_conv2 = tf.layers.conv2d(inception_3_conv1, 96, [3, 3], strides=[1, 1], padding=\"SAME\", activation=tf.nn.relu)\n",
    "    inception_3_conv3 = tf.layers.conv2d(inception_3_conv2, 96, [3, 3], strides=strides, padding=\"SAME\")\n",
    "    inception_3_bn1 = tf.layers.batch_normalization(inception_3_conv3, training=is_training)\n",
    "    inception_3 = tf.nn.relu(inception_3_bn1)\n",
    "    \n",
    "    inception_4_pool1 = tf.nn.pool(input_layer, [3, 3], pool_type, \"SAME\", strides=strides)\n",
    "    if proj_size == 0:\n",
    "        inception_4 = tf.nn.relu(inception_4_pool1)  # pass through layer if proj_size is 0\n",
    "    else:\n",
    "        inception_4_conv1 = tf.layers.conv2d(inception_4_pool1, proj_size, [1, 1], padding=\"SAME\")\n",
    "        inception_4_bn1 = tf.layers.batch_normalization(inception_4_conv1, training=is_training)\n",
    "        inception_4 = tf.nn.relu(inception_4_bn1)\n",
    "    \n",
    "    inception_out = tf.concat([inception_1, inception_2, inception_3, inception_4], -1)\n",
    "    return inception_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GoogleNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def GoogleNet(X, is_training, keep_prob=1.0):\n",
    "    conv_1 = tf.layers.conv2d(X, 64, [7, 7], strides=[2, 2], padding=\"SAME\", activation=tf.nn.relu)\n",
    "    pool_1 = tf.nn.max_pool(conv_1, [1, 3, 3, 1], [1, 2, 2, 1], \"SAME\")\n",
    "    norm_1 = tf.layers.batch_normalization(pool_1, training=is_training)\n",
    "    conv_2 = tf.layers.conv2d(norm_1, 192, [3, 3], strides=[1, 1], padding=\"SAME\", activation=tf.nn.relu)\n",
    "    pool_2 = tf.nn.max_pool(conv_2, [1, 3, 3, 1], [1, 2, 2, 1], \"SAME\")\n",
    "    norm_2 = tf.layers.batch_normalization(pool_2, training=is_training)\n",
    "    \n",
    "    inception_1a = Inception(norm_2, 64, 64, 64, 64, 96, \"AVG\", 32, False)\n",
    "    inception_1b = Inception(inception_1a, 64, 64, 96, 64, 96, \"AVG\", 64, False)\n",
    "    inception_1c = Inception(inception_1b, 0, 128, 160, 64, 96, \"MAX\", 0, True)\n",
    "    inception_2a = Inception(inception_1c, 224, 64, 96, 96, 128, \"AVG\", 128, False)\n",
    "    inception_2b = Inception(inception_2a, 192, 96, 128, 96, 128, \"AVG\", 128, False)\n",
    "    inception_2c = Inception(inception_2b, 160, 128, 160, 128, 160, \"AVG\", 128, False)\n",
    "    inception_2d = Inception(inception_2c, 96, 128, 192, 160, 192, \"AVG\", 128, False)\n",
    "    inception_2e = Inception(inception_2d, 0, 128, 192, 192, 256, \"MAX\", 0, True)\n",
    "    inception_3a = Inception(inception_2e, 352, 192, 320, 160, 224, \"AVG\", 128, False)\n",
    "    inception_3b = Inception(inception_3a, 352, 192, 320, 192, 224, \"MAX\", 128, False)\n",
    "    \n",
    "    # The following pooling size is changed from the original paper due to different starting image sizes\n",
    "    pool_3 = tf.nn.pool(inception_3b, [4, 4], \"AVG\", \"VALID\", strides=[1, 1])\n",
    "    if keep_prob < 1.0:\n",
    "        pool_3 = tf.nn.dropout(pool_3, keep_prob)\n",
    "    y_out = tf.layers.dense(pool_3, 20)\n",
    "    return y_out[:, 0, 0, :]\n",
    "\n",
    "# Now we're going to feed a random batch into the model \n",
    "# and make sure the output is the right size\n",
    "X = tf.placeholder(tf.float32, [None, 128, 128, 3])\n",
    "y = tf.placeholder(tf.int64, [None])\n",
    "is_training = tf.placeholder(tf.bool)\n",
    "\n",
    "y_out = GoogleNet(X, is_training)\n",
    "total_loss = tf.nn.softmax_cross_entropy_with_logits(labels=tf.one_hot(y, 20), logits=y_out)\n",
    "mean_loss = tf.reduce_mean(total_loss)\n",
    "\n",
    "# define our optimizer\n",
    "optimizer = tf.train.AdamOptimizer(5e-4) # select optimizer and set learning rate\n",
    "train_step = optimizer.minimize(mean_loss)\n",
    "\n",
    "# batch normalization in tensorflow requires this extra dependency\n",
    "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "with tf.control_dependencies(extra_update_ops):\n",
    "    train_step = optimizer.minimize(mean_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 20)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "x = np.random.randn(64, 128, 128, 3)\n",
    "with tf.Session() as sess:\n",
    "    with tf.device(\"/cpu:0\"): #\"/cpu:0\" or \"/gpu:0\"\n",
    "        tf.global_variables_initializer().run()\n",
    "\n",
    "        ans = sess.run(y_out,feed_dict={X:x,is_training:True})\n",
    "        print(ans.shape)\n",
    "        print(np.array_equal(ans.shape, np.array([64, 20])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run the model returning total loss and total correct\n",
    "def run_model(session, predict, loss_val, Xd, yd,\n",
    "              epochs=1, batch_size=32, print_every=100,\n",
    "              training=None, plot_losses=False):\n",
    "    \n",
    "    # have tensorflow compute accuracy\n",
    "    correct_prediction = tf.equal(tf.argmax(predict,1), y)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    # shuffle indicies\n",
    "    train_indicies = np.arange(Xd.shape[0])\n",
    "    np.random.shuffle(train_indicies)\n",
    "\n",
    "    training_now = training is not None\n",
    "    \n",
    "    # setting up variables we want to compute (and optimizing)\n",
    "    # if we have a training function, add that to things we compute\n",
    "    variables = [mean_loss,correct_prediction,accuracy]\n",
    "    if training_now:\n",
    "        variables[-1] = training\n",
    "    \n",
    "    # counter \n",
    "    iter_cnt = 0\n",
    "    for e in range(epochs):\n",
    "        # keep track of losses and accuracy\n",
    "        correct = 0\n",
    "        losses = []\n",
    "        # make sure we iterate over the dataset once\n",
    "        for i in range(int(math.ceil(Xd.shape[0]/batch_size))):\n",
    "            # generate indicies for the batch\n",
    "            start_idx = (i*batch_size)%Xd.shape[0]\n",
    "            idx = train_indicies[start_idx:start_idx+batch_size]\n",
    "            \n",
    "            # create a feed dictionary for this batch\n",
    "            feed_dict = {X: Xd[idx,:],\n",
    "                         y: yd[idx],\n",
    "                         is_training: training_now }\n",
    "            # get batch size\n",
    "            actual_batch_size = yd[idx].shape[0]\n",
    "            \n",
    "            # have tensorflow compute loss and correct predictions\n",
    "            # and (if given) perform a training step\n",
    "            loss, corr, _ = session.run(variables,feed_dict=feed_dict)\n",
    "            \n",
    "            # aggregate performance stats\n",
    "            losses.append(loss*actual_batch_size)\n",
    "            correct += np.sum(corr)\n",
    "            \n",
    "            # print every now and then\n",
    "            if training_now and (iter_cnt % print_every) == 0:\n",
    "                print(\"Iteration {0}: with minibatch training loss = {1:.3g} and accuracy of {2:.2g}\"\\\n",
    "                      .format(iter_cnt,loss,np.sum(corr)/actual_batch_size))\n",
    "            iter_cnt += 1\n",
    "        total_correct = correct/Xd.shape[0]\n",
    "        total_loss = np.sum(losses)/Xd.shape[0]\n",
    "        print(\"Epoch {2}, Overall loss = {0:.3g} and accuracy of {1:.3g}\"\\\n",
    "              .format(total_loss,total_correct,e+1))\n",
    "        if plot_losses:\n",
    "            plt.plot(losses)\n",
    "            plt.grid(True)\n",
    "            plt.title('Epoch {} Loss'.format(e+1))\n",
    "            plt.xlabel('minibatch number')\n",
    "            plt.ylabel('minibatch loss')\n",
    "            plt.show()\n",
    "    return total_loss,total_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'Placeholder' with dtype float\n\t [[Node: Placeholder = Placeholder[dtype=DT_FLOAT, shape=[], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op u'Placeholder', defined at:\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/Library/Python/2.7/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/Library/Python/2.7/site-packages/traitlets/config/application.py\", line 592, in launch_instance\n    app.start()\n  File \"/Library/Python/2.7/site-packages/ipykernel/kernelapp.py\", line 403, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Library/Python/2.7/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Library/Python/2.7/site-packages/tornado/ioloop.py\", line 883, in start\n    handler_func(fd_obj, events)\n  File \"/Library/Python/2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Library/Python/2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Library/Python/2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Library/Python/2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Library/Python/2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Library/Python/2.7/site-packages/ipykernel/kernelbase.py\", line 260, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Library/Python/2.7/site-packages/ipykernel/kernelbase.py\", line 212, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Library/Python/2.7/site-packages/ipykernel/kernelbase.py\", line 370, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Library/Python/2.7/site-packages/ipykernel/ipkernel.py\", line 175, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Library/Python/2.7/site-packages/IPython/core/interactiveshell.py\", line 2902, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Library/Python/2.7/site-packages/IPython/core/interactiveshell.py\", line 3006, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Library/Python/2.7/site-packages/IPython/core/interactiveshell.py\", line 3066, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-3-bb843b1ded95>\", line 29, in <module>\n    X = tf.placeholder(tf.float32, [None, 128, 128, 3])\n  File \"/Library/Python/2.7/site-packages/tensorflow/python/ops/array_ops.py\", line 1507, in placeholder\n    name=name)\n  File \"/Library/Python/2.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1997, in _placeholder\n    name=name)\n  File \"/Library/Python/2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"/Library/Python/2.7/site-packages/tensorflow/python/framework/ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/Library/Python/2.7/site-packages/tensorflow/python/framework/ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder' with dtype float\n\t [[Node: Placeholder = Placeholder[dtype=DT_FLOAT, shape=[], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-c7e922cb1c12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_out\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmean_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Validation'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_out\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmean_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-34accdce17ed>\u001b[0m in \u001b[0;36mrun_model\u001b[0;34m(session, predict, loss_val, Xd, yd, epochs, batch_size, print_every, training, plot_losses)\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;31m# have tensorflow compute loss and correct predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;31m# and (if given) perform a training step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;31m# aggregate performance stats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1052\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Placeholder' with dtype float\n\t [[Node: Placeholder = Placeholder[dtype=DT_FLOAT, shape=[], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op u'Placeholder', defined at:\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/Library/Python/2.7/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/Library/Python/2.7/site-packages/traitlets/config/application.py\", line 592, in launch_instance\n    app.start()\n  File \"/Library/Python/2.7/site-packages/ipykernel/kernelapp.py\", line 403, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Library/Python/2.7/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Library/Python/2.7/site-packages/tornado/ioloop.py\", line 883, in start\n    handler_func(fd_obj, events)\n  File \"/Library/Python/2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Library/Python/2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Library/Python/2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Library/Python/2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Library/Python/2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Library/Python/2.7/site-packages/ipykernel/kernelbase.py\", line 260, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Library/Python/2.7/site-packages/ipykernel/kernelbase.py\", line 212, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Library/Python/2.7/site-packages/ipykernel/kernelbase.py\", line 370, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Library/Python/2.7/site-packages/ipykernel/ipkernel.py\", line 175, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Library/Python/2.7/site-packages/IPython/core/interactiveshell.py\", line 2902, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Library/Python/2.7/site-packages/IPython/core/interactiveshell.py\", line 3006, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Library/Python/2.7/site-packages/IPython/core/interactiveshell.py\", line 3066, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-3-bb843b1ded95>\", line 29, in <module>\n    X = tf.placeholder(tf.float32, [None, 128, 128, 3])\n  File \"/Library/Python/2.7/site-packages/tensorflow/python/ops/array_ops.py\", line 1507, in placeholder\n    name=name)\n  File \"/Library/Python/2.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1997, in _placeholder\n    name=name)\n  File \"/Library/Python/2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"/Library/Python/2.7/site-packages/tensorflow/python/framework/ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/Library/Python/2.7/site-packages/tensorflow/python/framework/ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder' with dtype float\n\t [[Node: Placeholder = Placeholder[dtype=DT_FLOAT, shape=[], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "print('Training')\n",
    "run_model(sess,y_out,mean_loss,X_train,y_train,1,32,1,train_step,True)\n",
    "print('Validation')\n",
    "run_model(sess,y_out,mean_loss,X_val,y_val,1,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
